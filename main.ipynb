{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé≠ Identity-Aware Segmentation with SAM 3 & InsightFace\n",
    "\n",
    "**‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ:** ‡∏£‡∏∞‡∏ö‡∏ö Segmentation ‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏à‡∏≥‡∏ï‡∏±‡∏ß‡∏ï‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏ß‡∏á IVE\n",
    "\n",
    "**‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ:**\n",
    "- SAM 3 (Segment Anything Model 3) - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Segmentation\n",
    "- InsightFace - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Face Recognition\n",
    "- RTX 6000 (48GB VRAM) Optimized\n",
    "\n",
    "**‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å IVE 6 ‡∏Ñ‡∏ô:** Wonyoung, Yujin, Gaeul, Liz, Leeseo, Rei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìã Table of Contents\n",
    "\n",
    "1. [Environment Setup](#section-1)\n",
    "2. [Face Embedding Database](#section-2)\n",
    "3. [Identity Matching](#section-3)\n",
    "4. [SAM 3 Engine](#section-4)\n",
    "5. [Integration Pipeline](#section-5)\n",
    "6. [Gradio UI](#section-6)\n",
    "7. [Video Inference](#section-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section-1'></a>\n",
    "## Section 1: Environment Setup üîß\n",
    "\n",
    "‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á dependencies ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö RTX 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dependencies ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 1.1: Install Dependencies\n",
    "# =============================================================================\n",
    "\n",
    "# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PyTorch 2.5.1 ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö CUDA 12.1\n",
    "!pip install -q torch==2.5.1+cu121 torchvision==0.20.1+cu121 torchaudio==2.5.1+cu121 --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Face Recognition ‡πÅ‡∏•‡∏∞ Segmentation libraries\n",
    "!pip install -q insightface onnxruntime-gpu opencv-python Pillow\n",
    "\n",
    "# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á UI ‡πÅ‡∏•‡∏∞ Utilities\n",
    "!pip install -q gradio matplotlib scikit-learn scipy\n",
    "!pip install -q huggingface-hub transformers accelerate\n",
    "\n",
    "# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Video Processing\n",
    "!pip install -q tqdm imageio imageio-ffmpeg av\n",
    "\n",
    "print(\"‚úÖ Dependencies ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ SAM 3 directory ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß\n",
      "/root/SEGMENTATION_IVE/sam3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/SEGMENTATION_IVE/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/SEGMENTATION_IVE\n",
      "‚úÖ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á SAM 3 ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 1.2: Clone ‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á SAM 3\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå sam3 ‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "if not os.path.exists(\"sam3\"):\n",
    "    print(\"üì• ‡∏Å‡∏≥‡∏•‡∏±‡∏á clone SAM 3 repository...\")\n",
    "    !git clone https://github.com/facebookresearch/sam3.git\n",
    "    print(\"‚úÖ Clone SAM 3 ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!\")\n",
    "else:\n",
    "    print(\"üìÅ SAM 3 directory ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß\")\n",
    "\n",
    "# ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô directory ‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á\n",
    "%cd sam3\n",
    "!pip install -q -e \".[notebooks]\"\n",
    "%cd ..\n",
    "\n",
    "print(\"‚úÖ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á SAM 3 ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà HuggingFace Token ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\n",
      "   - ‡πÑ‡∏õ‡∏ó‡∏µ‡πà https://huggingface.co/settings/tokens\n",
      "   - ‡∏™‡∏£‡πâ‡∏≤‡∏á token ‡πÉ‡∏´‡∏°‡πà (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ access ‡∏ñ‡∏∂‡∏á SAM 3)\n",
      "   - ‡∏ß‡∏≤‡∏á token ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà:\n",
      "‚úÖ Login HuggingFace ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 1.3: HuggingFace Login\n",
    "# =============================================================================\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "print(\"üîë ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà HuggingFace Token ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\")\n",
    "print(\"   - ‡πÑ‡∏õ‡∏ó‡∏µ‡πà https://huggingface.co/settings/tokens\")\n",
    "print(\"   - ‡∏™‡∏£‡πâ‡∏≤‡∏á token ‡πÉ‡∏´‡∏°‡πà (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ access ‡∏ñ‡∏∂‡∏á SAM 3)\")\n",
    "print(\"   - ‡∏ß‡∏≤‡∏á token ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà:\")\n",
    "login(token=\"\")\n",
    "\n",
    "print(\"‚úÖ Login HuggingFace ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üñ•Ô∏è  GPU Information\n",
      "============================================================\n",
      "‚úÖ GPU: NVIDIA RTX 6000 Ada Generation\n",
      "üìå CUDA Version: 12.1\n",
      "üìå Total VRAM: 47.37 GB\n",
      "üìå Compute Capability: 8.9\n",
      "‚úÖ bfloat16 supported!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 1.4: Verify GPU ‡πÅ‡∏•‡∏∞ CUDA\n",
    "# =============================================================================\n",
    "\n",
    "import torch\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üñ•Ô∏è  GPU Information\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"‚úÖ GPU: {gpu_name}\")\n",
    "    \n",
    "    cuda_version = torch.version.cuda\n",
    "    print(f\"üìå CUDA Version: {cuda_version}\")\n",
    "    \n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "    print(f\"üìå Total VRAM: {total_memory:.2f} GB\")\n",
    "    \n",
    "    major = torch.cuda.get_device_capability(0)[0]\n",
    "    minor = torch.cuda.get_device_capability(0)[1]\n",
    "    print(f\"üìå Compute Capability: {major}.{minor}\")\n",
    "    \n",
    "    if major >= 8:\n",
    "        print(\"‚úÖ bfloat16 supported!\")\n",
    "else:\n",
    "    print(\"‚ùå CUDA not available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 1.5: Import All Libraries\n",
    "# =============================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Face Recognition\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "# SAM 3 (Facebook Hugging Face)\n",
    "from transformers import Sam3Model, Sam3Processor\n",
    "\n",
    "# UI\n",
    "import gradio as gr\n",
    "\n",
    "# Utilities\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section-2'></a>\n",
    "## Section 2: Face Embedding Database üë§\n",
    "\n",
    "‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Face Embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å IVE 6 ‡∏Ñ‡∏ô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î InsightFace model (buffalo_l)...\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: ./insightface_models/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: ./insightface_models/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: ./insightface_models/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: ./insightface_models/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: ./insightface_models/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "‚úÖ InsightFace model ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!\n",
      "‚úÖ Yujin: 16 faces extracted\n",
      "‚úÖ Wonyoung: 22 faces extracted\n",
      "‚úÖ Gaeul: 18 faces extracted\n",
      "‚úÖ Liz: 25 faces extracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Leeseo: 24 faces extracted\n",
      "‚úÖ Rei: 17 faces extracted\n",
      "\n",
      "‚úÖ Face Embedding Database ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô! (6 ‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 2: Face Embedding Database Creation\n",
    "# =============================================================================\n",
    "\n",
    "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Mapping ‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å\n",
    "MEMBER_MAPPING = {\n",
    "    \"An_Yujin\": \"Yujin\",\n",
    "    \"Jang_Wonyoung\": \"Wonyoung\",\n",
    "    \"Kim_Gaeul\": \"Gaeul\",\n",
    "    \"Kim_Jiwon\": \"Liz\",\n",
    "    \"Lee_Hyunseo\": \"Leeseo\",\n",
    "    \"Naoi_Rei\": \"Rei\"\n",
    "}\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î InsightFace\n",
    "print(\"üöÄ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î InsightFace model (buffalo_l)...\")\n",
    "face_analyzer = FaceAnalysis(\n",
    "    name='buffalo_l',\n",
    "    root='./insightface_models',\n",
    "    providers=['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
    ")\n",
    "face_analyzer.prepare(ctx_id=0, det_size=(640, 640))\n",
    "print(\"‚úÖ InsightFace model ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!\")\n",
    "\n",
    "def normalize_embedding(embedding):\n",
    "    \"\"\"‡∏ó‡∏≥ L2 Normalization ‡∏ö‡∏ô face embedding\"\"\"\n",
    "    norm = np.linalg.norm(embedding)\n",
    "    if norm < 1e-10:\n",
    "        return embedding\n",
    "    return embedding / norm\n",
    "\n",
    "def create_embedding_database(dataset_path, face_analyzer, member_mapping):\n",
    "    \"\"\"‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• face embeddings\"\"\"\n",
    "    embeddings_db = {}\n",
    "    \n",
    "    for folder_name, member_name in member_mapping.items():\n",
    "        member_path = Path(dataset_path) / folder_name\n",
    "        \n",
    "        if not member_path.exists():\n",
    "            print(f\"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå: {member_path}\")\n",
    "            continue\n",
    "        \n",
    "        image_files = list(member_path.glob('*.jpg')) + list(member_path.glob('*.png'))\n",
    "        member_embeddings = []\n",
    "        \n",
    "        for img_path in image_files:\n",
    "            img_bgr = cv2.imread(str(img_path))\n",
    "            if img_bgr is None:\n",
    "                continue\n",
    "            \n",
    "            faces = face_analyzer.get(img_bgr)\n",
    "            if len(faces) > 0:\n",
    "                face = max(faces, key=lambda f: (f.bbox[2]-f.bbox[0])*(f.bbox[3]-f.bbox[1]))\n",
    "                normalized_embedding = normalize_embedding(face.embedding)\n",
    "                member_embeddings.append(normalized_embedding)\n",
    "        \n",
    "        if len(member_embeddings) > 0:\n",
    "            avg_embedding = np.mean(member_embeddings, axis=0)\n",
    "            avg_embedding = normalize_embedding(avg_embedding)\n",
    "            embeddings_db[member_name] = avg_embedding\n",
    "            print(f\"‚úÖ {member_name}: {len(member_embeddings)} faces extracted\")\n",
    "    \n",
    "    return embeddings_db\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings database\n",
    "embeddings_db = create_embedding_database(\"Dataset\", face_analyzer, MEMBER_MAPPING)\n",
    "print(f\"\\n‚úÖ Face Embedding Database ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô! ({len(embeddings_db)} ‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section-3'></a>\n",
    "## Section 3: Identity Matching üéØ\n",
    "\n",
    "‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏∏‡∏ï‡∏±‡∏ß‡∏ï‡∏ô‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å IVE ‡∏à‡∏≤‡∏Å‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
    "‡πÉ‡∏ä‡πâ Cosine Similarity ‡πÅ‡∏•‡∏∞ Hungarian Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Identity matching functions loaded!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 3: Identity Matching Functions\n",
    "# =============================================================================\n",
    "\n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    \"\"\"‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì cosine similarity ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á 2 embeddings\"\"\"\n",
    "    return np.dot(embedding1, embedding2)\n",
    "\n",
    "def hungarian_matching(faces, embeddings_db, threshold=0.45):\n",
    "    \"\"\"\n",
    "    ‡πÉ‡∏ä‡πâ Hungarian Algorithm ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏Å‡∏±‡∏ö‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏ó‡∏µ‡πà optimal\n",
    "    ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏¢‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ñ‡∏π‡∏Å‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô\n",
    "    \"\"\"\n",
    "    if len(faces) == 0 or len(embeddings_db) == 0:\n",
    "        return []\n",
    "    \n",
    "    member_names = list(embeddings_db.keys())\n",
    "    member_embeddings = [embeddings_db[name] for name in member_names]\n",
    "    \n",
    "    num_faces = len(faces)\n",
    "    num_members = len(member_names)\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Similarity Matrix\n",
    "    similarity_matrix = np.zeros((num_faces, num_members))\n",
    "    \n",
    "    for i, face in enumerate(faces):\n",
    "        face_embedding = face.embedding / (np.linalg.norm(face.embedding) + 1e-10)\n",
    "        for j, member_emb in enumerate(member_embeddings):\n",
    "            similarity = cosine_similarity(face_embedding, member_emb)\n",
    "            similarity_matrix[i, j] = similarity\n",
    "    \n",
    "    # ‡πÉ‡∏ä‡πâ Hungarian Algorithm\n",
    "    cost_matrix = -similarity_matrix\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    \n",
    "    matches = [None] * num_faces\n",
    "    \n",
    "    for face_idx, member_idx in zip(row_ind, col_ind):\n",
    "        similarity = similarity_matrix[face_idx, member_idx]\n",
    "        if similarity >= threshold:\n",
    "            member_name = member_names[member_idx]\n",
    "            matches[face_idx] = (face_idx, member_name, similarity)\n",
    "    \n",
    "    return matches\n",
    "\n",
    "def identify_all_members(image_bgr, face_analyzer, embeddings_db, threshold=0.45):\n",
    "    \"\"\"‡∏£‡∏∞‡∏ö‡∏∏‡∏ï‡∏±‡∏ß‡∏ï‡∏ô‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å IVE ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏†‡∏≤‡∏û\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    faces = face_analyzer.get(image_bgr)\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        print(\"‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\")\n",
    "        return results\n",
    "    \n",
    "    print(f\"üîç ‡∏û‡∏ö {len(faces)} ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\")\n",
    "    \n",
    "    matches = hungarian_matching(faces, embeddings_db, threshold)\n",
    "    \n",
    "    for i, face in enumerate(faces):\n",
    "        bbox = face.bbox.astype(int).tolist()\n",
    "        \n",
    "        if matches[i] is not None:\n",
    "            _, member_name, similarity = matches[i]\n",
    "            results.append({\n",
    "                'name': member_name,\n",
    "                'bbox': bbox,\n",
    "                'similarity': float(similarity)\n",
    "            })\n",
    "            print(f\"   ‚úÖ {member_name}: similarity={similarity:.4f}\")\n",
    "        else:\n",
    "            results.append({\n",
    "                'name': 'Unknown',\n",
    "                'bbox': bbox,\n",
    "                'similarity': None\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"‚úÖ Identity matching functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section-4'></a>\n",
    "## Section 4: SAM 3 Engine ‚úÇÔ∏è\n",
    "\n",
    "‡πÇ‡∏´‡∏•‡∏î SAM 3 ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß SAM 3 Engine: Using device = cuda\n",
      "\n",
      "üì¶ Loading SAM 3 Model...\n",
      "‚úÖ SAM 3 Model loaded successfully!\n",
      "‚úÖ SAM 3 segmentation functions ready!\n",
      "   - segment_by_box(): ‡∏™‡∏£‡πâ‡∏≤‡∏á mask ‡∏à‡∏≤‡∏Å bounding box\n",
      "   - segment_by_points(): ‡∏™‡∏£‡πâ‡∏≤‡∏á mask ‡∏à‡∏≤‡∏Å points\n",
      "   - refine_mask_with_points(): ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á mask ‡∏î‡πâ‡∏ß‡∏¢ points\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 4: SAM 3 Engine (Improved)\n",
    "# =============================================================================\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ precision ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö RTX 6000\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üîß SAM 3 Engine: Using device = {DEVICE}\")\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î SAM 3 Model ‡∏à‡∏≤‡∏Å Hugging Face repo: facebook/sam3\n",
    "print(\"\\nüì¶ Loading SAM 3 Model...\")\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sam3_repo_root = Path(\"sam3\").resolve()\n",
    "if str(sam3_repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(sam3_repo_root))\n",
    "\n",
    "from sam3 import build_sam3_image_model\n",
    "from sam3.model.sam3_image_processor import Sam3Processor\n",
    "\n",
    "sam3_model = build_sam3_image_model(\n",
    "    device=DEVICE.type,\n",
    "    load_from_HF=True,\n",
    "    compile=False,\n",
    "    enable_inst_interactivity=True,\n",
    "    eval_mode=True,\n",
    "    checkpoint_path=None,\n",
    "    bpe_path=None,\n",
    "    enable_segmentation=True\n",
    ")\n",
    "sam3_processor = Sam3Processor(sam3_model)\n",
    "sam3_model.eval()\n",
    "\n",
    "print(\"‚úÖ SAM 3 Model loaded successfully!\")\n",
    "\n",
    "def segment_by_box(image_pil, box_xyxy, multimask_output=True):\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á mask ‡∏à‡∏≤‡∏Å bounding box (xyxy)\n",
    "    \n",
    "    Args:\n",
    "        image_pil: PIL Image\n",
    "        box_xyxy: [x1, y1, x2, y2]\n",
    "        multimask_output: ‡∏ñ‡πâ‡∏≤ True ‡∏à‡∏∞ return ‡∏´‡∏•‡∏≤‡∏¢ mask ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏±‡∏ô‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\n",
    "    \"\"\"\n",
    "    inference_state = sam3_processor.set_image(image_pil)\n",
    "    input_box = np.array(box_xyxy, dtype=np.float32)[None, :]\n",
    "\n",
    "    masks, scores, _ = sam3_model.predict_inst(\n",
    "        inference_state,\n",
    "        point_coords=None,\n",
    "        point_labels=None,\n",
    "        box=input_box,\n",
    "        multimask_output=multimask_output,\n",
    "    )\n",
    "\n",
    "    scores_np = np.asarray(scores)\n",
    "    \n",
    "    if multimask_output:\n",
    "        # Return the best mask based on score\n",
    "        best_idx = int(np.argmax(scores_np))\n",
    "        best_mask = np.asarray(masks[best_idx])\n",
    "    else:\n",
    "        best_mask = np.asarray(masks[0])\n",
    "\n",
    "    return (best_mask > 0).astype(np.uint8)\n",
    "\n",
    "\n",
    "def segment_by_points(image_pil, point_coords, point_labels, multimask_output=True):\n",
    "    \"\"\"\n",
    "    Segment ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ point prompts\n",
    "    \n",
    "    Args:\n",
    "        image_pil: PIL Image\n",
    "        point_coords: [[x1, y1], [x2, y2], ...]\n",
    "        point_labels: [1, 0, ...] (1=positive, 0=negative)\n",
    "        multimask_output: ‡∏ñ‡πâ‡∏≤ True ‡∏à‡∏∞ return ‡∏´‡∏•‡∏≤‡∏¢ mask\n",
    "    \"\"\"\n",
    "    inference_state = sam3_processor.set_image(image_pil)\n",
    "    \n",
    "    point_coords_np = np.array(point_coords, dtype=np.float32)\n",
    "    point_labels_np = np.array(point_labels, dtype=np.int32)\n",
    "    \n",
    "    masks, scores, _ = sam3_model.predict_inst(\n",
    "        inference_state,\n",
    "        point_coords=point_coords_np[None, :, :],\n",
    "        point_labels=point_labels_np[None, :],\n",
    "        box=None,\n",
    "        multimask_output=multimask_output,\n",
    "    )\n",
    "    \n",
    "    scores_np = np.asarray(scores)\n",
    "    \n",
    "    if multimask_output:\n",
    "        best_idx = int(np.argmax(scores_np))\n",
    "        best_mask = np.asarray(masks[best_idx])\n",
    "    else:\n",
    "        best_mask = np.asarray(masks[0])\n",
    "    \n",
    "    return (best_mask > 0).astype(np.uint8)\n",
    "\n",
    "\n",
    "def refine_mask_with_points(image_pil, initial_mask, point_coords, point_labels):\n",
    "    \"\"\"\n",
    "    ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á mask ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ point prompts ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°\n",
    "    \"\"\"\n",
    "    # Find the bounding box of the initial mask\n",
    "    ys, xs = np.where(initial_mask > 0)\n",
    "    if len(xs) == 0:\n",
    "        return initial_mask\n",
    "    \n",
    "    x1, y1 = xs.min(), ys.min()\n",
    "    x2, y2 = xs.max(), ys.max()\n",
    "    \n",
    "    # Add margin\n",
    "    margin = 20\n",
    "    x1 = max(0, x1 - margin)\n",
    "    y1 = max(0, y1 - margin)\n",
    "    x2 = min(image_pil.width - 1, x2 + margin)\n",
    "    y2 = min(image_pil.height - 1, y2 + margin)\n",
    "    \n",
    "    # Segment with box + points\n",
    "    inference_state = sam3_processor.set_image(image_pil)\n",
    "    \n",
    "    input_box = np.array([x1, y1, x2, y2], dtype=np.float32)[None, :]\n",
    "    point_coords_np = np.array(point_coords, dtype=np.float32)\n",
    "    point_labels_np = np.array(point_labels, dtype=np.int32)\n",
    "    \n",
    "    masks, scores, _ = sam3_model.predict_inst(\n",
    "        inference_state,\n",
    "        point_coords=point_coords_np[None, :, :],\n",
    "        point_labels=point_labels_np[None, :],\n",
    "        box=input_box,\n",
    "        multimask_output=True,\n",
    "    )\n",
    "    \n",
    "    scores_np = np.asarray(scores)\n",
    "    best_idx = int(np.argmax(scores_np))\n",
    "    best_mask = np.asarray(masks[best_idx])\n",
    "    \n",
    "    return (best_mask > 0).astype(np.uint8)\n",
    "\n",
    "\n",
    "print(\"‚úÖ SAM 3 segmentation functions ready!\")\n",
    "print(\"   - segment_by_box(): ‡∏™‡∏£‡πâ‡∏≤‡∏á mask ‡∏à‡∏≤‡∏Å bounding box\")\n",
    "print(\"   - segment_by_points(): ‡∏™‡∏£‡πâ‡∏≤‡∏á mask ‡∏à‡∏≤‡∏Å points\")\n",
    "print(\"   - refine_mask_with_points(): ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á mask ‡∏î‡πâ‡∏ß‡∏¢ points\")\n",
    "\n",
    "\n",
    "\n",
    "def segment_with_negative_prompts(image_pil, target_bbox, other_face_bboxes, other_expansion=2.0):\n",
    "    \"\"\"\n",
    "    Segment target person while avoiding other people using negative point prompts.\n",
    "    \n",
    "    Args:\n",
    "        image_pil: PIL Image\n",
    "        target_bbox: [x1, y1, x2, y2] for target person body\n",
    "        other_face_bboxes: List of face bboxes for other people to avoid\n",
    "        other_expansion: Scale to expand other face bboxes for negative regions\n",
    "    \"\"\"\n",
    "    inference_state = sam3_processor.set_image(image_pil)\n",
    "    \n",
    "    # Positive: center of target body bbox\n",
    "    tx1, ty1, tx2, ty2 = target_bbox\n",
    "    target_cx = (tx1 + tx2) / 2\n",
    "    target_cy = (ty1 + ty2) / 2\n",
    "    \n",
    "    point_coords = [[target_cx, target_cy]]\n",
    "    point_labels = [1]  # positive\n",
    "    \n",
    "    # Negative points: centers of other people's face bboxes (expanded)\n",
    "    for face_bbox in other_face_bboxes:\n",
    "        fx1, fy1, fx2, fy2 = face_bbox\n",
    "        # Expand face bbox to estimate body region\n",
    "        fw = fx2 - fx1\n",
    "        fh = fy2 - fy1\n",
    "        face_cx = (fx1 + fx2) / 2\n",
    "        face_cy = (fy1 + fy2) / 2\n",
    "        \n",
    "        # Add negative point at center of other person's estimated body\n",
    "        neg_cx = face_cx\n",
    "        neg_cy = face_cy + fh * 1.5  # Below face (body center estimate)\n",
    "        \n",
    "        # Clamp to image bounds\n",
    "        neg_cx = max(0, min(image_pil.width - 1, neg_cx))\n",
    "        neg_cy = max(0, min(image_pil.height - 1, neg_cy))\n",
    "        \n",
    "        point_coords.append([neg_cx, neg_cy])\n",
    "        point_labels.append(0)  # negative\n",
    "    \n",
    "    input_box = np.array(target_bbox, dtype=np.float32)[None, :]\n",
    "    \n",
    "    masks, scores, _ = sam3_model.predict_inst(\n",
    "        inference_state,\n",
    "        point_coords=np.array(point_coords, dtype=np.float32)[None],\n",
    "        point_labels=np.array(point_labels, dtype=np.int32)[None],\n",
    "        box=input_box,\n",
    "        multimask_output=True,\n",
    "    )\n",
    "    \n",
    "    best_idx = int(np.argmax(np.asarray(scores)))\n",
    "    return (np.asarray(masks[best_idx]) > 0).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section-5'></a>\n",
    "## Section 5: Integration Pipeline üîó\n",
    "\n",
    "‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á InsightFace ‡∏Å‡∏±‡∏ö SAM 3 - The Magic Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Integration Pipeline ready!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 5: Integration Pipeline\n",
    "# =============================================================================\n",
    "\n",
    "def face_to_body_bbox(face_bbox, img_shape, width_scale=3.0, height_top_scale=1.2, height_bottom_scale=5):\n",
    "    \"\"\"‡∏Ç‡∏¢‡∏≤‡∏¢ face bbox ‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏ï‡∏±‡∏ß\"\"\"\n",
    "    x1, y1, x2, y2 = face_bbox.astype(float)\n",
    "    face_center_x = (x1 + x2) / 2.0\n",
    "    face_center_y = (y1 + y2) / 2.0\n",
    "    face_width = x2 - x1\n",
    "    face_height = y2 - y1\n",
    "    \n",
    "    img_h, img_w = img_shape\n",
    "    \n",
    "    half_body_width = (face_width * width_scale) / 2.0\n",
    "    body_x1 = face_center_x - half_body_width\n",
    "    body_x2 = face_center_x + half_body_width\n",
    "    \n",
    "    body_y1 = face_center_y - (face_height * height_top_scale)\n",
    "    body_y2 = face_center_y + (face_height * height_bottom_scale)\n",
    "    \n",
    "    body_x1 = max(0, body_x1)\n",
    "    body_y1 = max(0, body_y1)\n",
    "    body_x2 = min(img_w - 1, body_x2)\n",
    "    body_y2 = min(img_h - 1, body_y2)\n",
    "    \n",
    "    return np.array([body_x1, body_y1, body_x2, body_y2], dtype=np.int32)\n",
    "\n",
    "def create_overlay(image_rgb, mask, color=[0, 255, 128], alpha=0.5):\n",
    "    \"\"\"‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û overlay ‡πÇ‡∏î‡∏¢‡πÉ‡∏™‡πà‡∏™‡∏µ‡∏ó‡∏±‡∏ö mask\"\"\"\n",
    "    overlay = image_rgb.copy()\n",
    "    mask_bool = mask.astype(bool)\n",
    "    color_layer = np.zeros_like(image_rgb)\n",
    "    color_layer[mask_bool] = color\n",
    "    overlay = cv2.addWeighted(overlay, 1.0, color_layer, alpha, 0)\n",
    "    return overlay\n",
    "\n",
    "def create_cutout(image_rgb, mask):\n",
    "    \"\"\"‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û cutout ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡πÇ‡∏õ‡∏£‡πà‡∏á‡πÉ‡∏™\"\"\"\n",
    "    mask_bool = mask.astype(bool)\n",
    "    alpha_channel = (mask_bool * 255).astype(np.uint8)\n",
    "    cutout_rgba = np.dstack((image_rgb, alpha_channel))\n",
    "    return cutout_rgba\n",
    "\n",
    "def segment_member(image_bgr, member_name, similarity_threshold=0.45, use_negative_prompts=True):\n",
    "    \"\"\"\n",
    "    Pipeline ‡∏´‡∏•‡∏±‡∏Å: ‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û + ‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å ‡∏Ñ‡∏∑‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö\n",
    "    \n",
    "    Args:\n",
    "        image_bgr: Input image in BGR format\n",
    "        member_name: Name of the member to segment\n",
    "        similarity_threshold: Face recognition threshold\n",
    "        use_negative_prompts: Whether to use negative prompts to avoid other people\n",
    "    \"\"\"\n",
    "    if member_name not in embeddings_db:\n",
    "        return None, None, None, None, f\"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö embedding ‡∏Ç‡∏≠‡∏á '{member_name}'\"\n",
    "    \n",
    "    target_embedding = embeddings_db[member_name]\n",
    "    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "    img_h, img_w = image_bgr.shape[:2]\n",
    "    \n",
    "    # Step 1: Identify all members\n",
    "    members = identify_all_members(image_bgr, face_analyzer, embeddings_db, similarity_threshold)\n",
    "    \n",
    "    target = None\n",
    "    other_face_bboxes = []\n",
    "    for m in members:\n",
    "        if m[\"name\"] == member_name:\n",
    "            target = m\n",
    "        else:\n",
    "            other_face_bboxes.append(m[\"bbox\"])  # Collect other people's face bboxes\n",
    "    \n",
    "    if target is None:\n",
    "        return None, None, None, None, f\"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö {member_name} ‡πÉ‡∏ô‡∏†‡∏≤‡∏û\"\n",
    "    \n",
    "    # Step 2: Expand face bbox to body bbox\n",
    "    face_bbox = np.array(target[\"bbox\"])\n",
    "    body_bbox = face_to_body_bbox(face_bbox, (img_h, img_w))\n",
    "    \n",
    "    # Step 3: SAM 3 Segmentation with negative prompts\n",
    "    image_pil = Image.fromarray(image_rgb)\n",
    "    \n",
    "    if use_negative_prompts and len(other_face_bboxes) > 0:\n",
    "        # Use negative prompts to avoid segmenting other people\n",
    "        mask = segment_with_negative_prompts(image_pil, body_bbox.tolist(), other_face_bboxes)\n",
    "    else:\n",
    "        # Fallback to simple box-based segmentation\n",
    "        mask = segment_by_box(image_pil, body_bbox.tolist())\n",
    "    \n",
    "    # Step 4: Clean up the mask\n",
    "    mask = clean_mask(mask, kernel_size=7)\n",
    "    \n",
    "    # Step 5: Create outputs\n",
    "    overlay = create_overlay(image_rgb, mask)\n",
    "    cutout = create_cutout(image_rgb, mask)\n",
    "    \n",
    "    # Create annotated image\n",
    "    annotated = image_rgb.copy()\n",
    "    for m in members:\n",
    "        x1, y1, x2, y2 = m[\"bbox\"]\n",
    "        is_target = (m[\"name\"] == member_name)\n",
    "        color_box = (0, 255, 0) if is_target else (200, 200, 200)\n",
    "        thickness = 3 if is_target else 1\n",
    "        cv2.rectangle(annotated, (x1, y1), (x2, y2), color_box, thickness)\n",
    "        if m[\"similarity\"]:\n",
    "            label = f\"{m['name']} ({m['similarity']:.2f})\"\n",
    "            cv2.putText(annotated, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color_box, 2)\n",
    "    \n",
    "    # Draw body bbox\n",
    "    bx1, by1, bx2, by2 = body_bbox\n",
    "    cv2.rectangle(annotated, (bx1, by1), (bx2, by2), (255, 0, 0), 2)\n",
    "    cv2.putText(annotated, \"Body BBox\", (bx1, by1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "    \n",
    "    status = f\"‚úÖ Found {member_name} (sim={target['similarity']:.3f})\"\n",
    "    if use_negative_prompts and len(other_face_bboxes) > 0:\n",
    "        status += f\", excluded {len(other_face_bboxes)} other(s)\"\n",
    "    \n",
    "    return overlay, cutout, annotated, mask, status\n",
    "\n",
    "print(\"‚úÖ Integration Pipeline ready!\")\n",
    "\n",
    "def clean_mask(mask, kernel_size=7, min_area_ratio=0.01):\n",
    "    \"\"\"\n",
    "    Clean up mask using morphological operations and connected component analysis.\n",
    "    \n",
    "    Args:\n",
    "        mask: Binary mask (0 or 1)\n",
    "        kernel_size: Size of morphological kernel\n",
    "        min_area_ratio: Minimum area ratio to keep (relative to image size)\n",
    "    \"\"\"\n",
    "    # Convert to uint8 if needed\n",
    "    if mask.dtype != np.uint8:\n",
    "        mask = (mask > 0).astype(np.uint8) * 255\n",
    "    else:\n",
    "        mask = (mask > 0).astype(np.uint8) * 255\n",
    "    \n",
    "    h, w = mask.shape\n",
    "    \n",
    "    # Create elliptical kernel for smoother results\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "    \n",
    "    # Close operation: fill small holes\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Open operation: remove small noise\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # Keep only the largest connected component\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask, connectivity=8)\n",
    "    \n",
    "    if num_labels > 1:\n",
    "        # Find largest component (skip background at index 0)\n",
    "        areas = stats[1:, cv2.CC_STAT_AREA]\n",
    "        min_area = h * w * min_area_ratio\n",
    "        \n",
    "        # Filter out very small components\n",
    "        valid_components = areas >= min_area\n",
    "        if np.any(valid_components):\n",
    "            largest_idx = np.argmax(areas * valid_components) + 1\n",
    "            mask = (labels == largest_idx).astype(np.uint8) * 255\n",
    "        else:\n",
    "            # If no component meets criteria, use largest anyway\n",
    "            largest_idx = np.argmax(areas) + 1\n",
    "            mask = (labels == largest_idx).astype(np.uint8) * 255\n",
    "    \n",
    "    return (mask > 0).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5.5: Association Pipeline üëï\n",
    "\n",
    "‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö prompt ‡πÅ‡∏ö‡∏ö \"Wonyoung's shirt\" - ‡∏´‡∏≤‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Association Pipeline ready!\n",
      "   - segment_associated_object(): ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö 'Wonyoung's shirt'\n",
      "   - segment_by_points(): ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö point-based segmentation\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 5.5: Association Pipeline (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö \"Wonyoung's shirt\")\n",
    "# =============================================================================\n",
    "\n",
    "def segment_associated_object(image_bgr, member_name, object_text, similarity_threshold=0.45):\n",
    "    \"\"\"\n",
    "    ‡∏´‡∏≤‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏• (‡πÄ‡∏ä‡πà‡∏ô \"Wonyoung's shirt\", \"Yujin's hair\")\n",
    "    \n",
    "    Logic:\n",
    "    1. ‡∏´‡∏≤ person mask ‡∏Ç‡∏≠‡∏á‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å\n",
    "    2. ‡πÉ‡∏ä‡πâ SAM 3 ‡∏Å‡∏±‡∏ö point prompts ‡∏ö‡∏£‡∏¥‡πÄ‡∏ß‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏à‡∏∞‡∏°‡∏µ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏\n",
    "    3. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡∏°‡∏µ spatial overlap ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Å‡∏±‡∏ö person mask\n",
    "    \"\"\"\n",
    "    if member_name not in embeddings_db:\n",
    "        return None, None, None, f\"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö embedding ‡∏Ç‡∏≠‡∏á '{member_name}'\"\n",
    "    \n",
    "    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "    img_h, img_w = image_bgr.shape[:2]\n",
    "    \n",
    "    # Step 1: Identify and get person mask\n",
    "    members = identify_all_members(image_bgr, face_analyzer, embeddings_db, similarity_threshold)\n",
    "    \n",
    "    target = None\n",
    "    for m in members:\n",
    "        if m[\"name\"] == member_name:\n",
    "            target = m\n",
    "            break\n",
    "    \n",
    "    if target is None:\n",
    "        return None, None, None, f\"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö {member_name} ‡πÉ‡∏ô‡∏†‡∏≤‡∏û\"\n",
    "    \n",
    "    # Step 2: Get person mask using body bbox\n",
    "    face_bbox = np.array(target[\"bbox\"])\n",
    "    body_bbox = face_to_body_bbox(face_bbox, (img_h, img_w))\n",
    "    \n",
    "    image_pil = Image.fromarray(image_rgb)\n",
    "    person_mask = segment_by_box(image_pil, body_bbox.tolist())\n",
    "    \n",
    "    # Step 3: Define region of interest based on object type\n",
    "    x1, y1, x2, y2 = body_bbox\n",
    "    \n",
    "    if \"shirt\" in object_text.lower() or \"dress\" in object_text.lower() or \"top\" in object_text.lower():\n",
    "        # Shirt is in the middle-lower part of body\n",
    "        roi_y1 = y1 + int((y2 - y1) * 0.25)  # Skip head\n",
    "        roi_y2 = y1 + int((y2 - y1) * 0.85)  # Above knees\n",
    "        roi_x1 = x1 + int((x2 - x1) * 0.1)\n",
    "        roi_x2 = x2 - int((x2 - x1) * 0.1)\n",
    "    elif \"hair\" in object_text.lower():\n",
    "        # Hair is above the face\n",
    "        roi_y1 = max(0, y1 - int((y2 - y1) * 0.8))\n",
    "        roi_y2 = y1 + int((y2 - y1) * 0.3)\n",
    "        roi_x1 = x1\n",
    "        roi_x2 = x2\n",
    "    elif \"pants\" in object_text.lower() or \"skirt\" in object_text.lower() or \"bottom\" in object_text.lower():\n",
    "        # Bottom is lower part\n",
    "        roi_y1 = y1 + int((y2 - y1) * 0.5)\n",
    "        roi_y2 = y2\n",
    "        roi_x1 = x1 + int((x2 - x1) * 0.15)\n",
    "        roi_x2 = x2 - int((x2 - x1) * 0.15)\n",
    "    elif \"shoes\" in object_text.lower() or \"foot\" in object_text.lower():\n",
    "        # Shoes at the bottom\n",
    "        roi_y1 = y1 + int((y2 - y1) * 0.8)\n",
    "        roi_y2 = y2\n",
    "        roi_x1 = x1 + int((x2 - x1) * 0.2)\n",
    "        roi_x2 = x2 - int((x2 - x1) * 0.2)\n",
    "    else:\n",
    "        # Default: use full body region\n",
    "        roi_y1 = y1\n",
    "        roi_y2 = y2\n",
    "        roi_x1 = x1\n",
    "        roi_x2 = x2\n",
    "    \n",
    "    # Clamp to image bounds\n",
    "    roi_x1 = max(0, roi_x1)\n",
    "    roi_y1 = max(0, roi_y1)\n",
    "    roi_x2 = min(img_w - 1, roi_x2)\n",
    "    roi_y2 = min(img_h - 1, roi_y2)\n",
    "    \n",
    "    # Step 4: Segment in ROI using SAM 3\n",
    "    roi_box = [roi_x1, roi_y1, roi_x2, roi_y2]\n",
    "    object_mask = segment_by_box(image_pil, roi_box)\n",
    "    \n",
    "    # Step 5: Find overlap with person mask\n",
    "    # Only keep parts of object_mask that overlap with person_mask\n",
    "    overlap_mask = object_mask & person_mask\n",
    "    \n",
    "    # Calculate overlap ratio\n",
    "    object_area = np.sum(object_mask > 0)\n",
    "    overlap_area = np.sum(overlap_mask > 0)\n",
    "    overlap_ratio = overlap_area / (object_area + 1e-10)\n",
    "    \n",
    "    # If overlap is too small, use the full object_mask in ROI\n",
    "    if overlap_ratio < 0.1:\n",
    "        print(f\"‚ö†Ô∏è Low overlap ({overlap_ratio:.2f}), using ROI-based mask\")\n",
    "        final_mask = object_mask\n",
    "    else:\n",
    "        final_mask = overlap_mask\n",
    "    \n",
    "    # Step 6: Create visualizations\n",
    "    # Person overlay (semi-transparent)\n",
    "    person_overlay = create_overlay(image_rgb, person_mask, color=[255, 105, 180], alpha=0.3)\n",
    "    \n",
    "    # Object overlay (different color)\n",
    "    object_overlay = create_overlay(person_overlay, final_mask, color=[0, 255, 128], alpha=0.6)\n",
    "    \n",
    "    # Annotated image\n",
    "    annotated = image_rgb.copy()\n",
    "    for m in members:\n",
    "        bx1, by1, bx2, by2 = m[\"bbox\"]\n",
    "        is_target = (m[\"name\"] == member_name)\n",
    "        color_box = (0, 255, 0) if is_target else (200, 200, 200)\n",
    "        thickness = 3 if is_target else 1\n",
    "        cv2.rectangle(annotated, (bx1, by1), (bx2, by2), color_box, thickness)\n",
    "        if m[\"similarity\"]:\n",
    "            label = f\"{m['name']} ({m['similarity']:.2f})\"\n",
    "            cv2.putText(annotated, label, (bx1, by1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color_box, 2)\n",
    "    \n",
    "    # Draw ROI box\n",
    "    cv2.rectangle(annotated, (roi_x1, roi_y1), (roi_x2, roi_y2), (255, 0, 0), 2)\n",
    "    cv2.putText(annotated, f\"ROI: {object_text}\", (roi_x1, roi_y1-10), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "    \n",
    "    status = f\"‚úÖ {member_name}'s {object_text}: overlap={overlap_ratio:.2f}\"\n",
    "    \n",
    "    return annotated, object_overlay, final_mask, status\n",
    "\n",
    "\n",
    "def segment_by_points(image_pil, point_coords, point_labels):\n",
    "    \"\"\"\n",
    "    Segment ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ point prompts (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö SAM 3)\n",
    "    \n",
    "    Args:\n",
    "        image_pil: PIL Image\n",
    "        point_coords: [[x1, y1], [x2, y2], ...]\n",
    "        point_labels: [1, 0, ...] (1=positive, 0=negative)\n",
    "    \"\"\"\n",
    "    inference_state = sam3_processor.set_image(image_pil)\n",
    "    \n",
    "    point_coords_np = np.array(point_coords, dtype=np.float32)\n",
    "    point_labels_np = np.array(point_labels, dtype=np.int32)\n",
    "    \n",
    "    masks, scores, _ = sam3_model.predict_inst(\n",
    "        inference_state,\n",
    "        point_coords=point_coords_np[None, :, :],\n",
    "        point_labels=point_labels_np[None, :],\n",
    "        box=None,\n",
    "        multimask_output=True,\n",
    "    )\n",
    "    \n",
    "    scores_np = np.asarray(scores)\n",
    "    best_idx = int(np.argmax(scores_np))\n",
    "    best_mask = np.asarray(masks[best_idx])\n",
    "    \n",
    "    return (best_mask > 0).astype(np.uint8)\n",
    "\n",
    "\n",
    "print(\"‚úÖ Association Pipeline ready!\")\n",
    "print(\"   - segment_associated_object(): ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö 'Wonyoung's shirt'\")\n",
    "print(\"   - segment_by_points(): ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö point-based segmentation\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section-6'></a>\n",
    "## Section 6: Gradio UI üé®\n",
    "\n",
    "‡∏™‡∏£‡πâ‡∏≤‡∏á Web Interface ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏£‡∏∞‡∏ö‡∏ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gradio UI created!\n",
      "‡∏£‡∏±‡∏ô‡∏î‡πâ‡∏ß‡∏¢: demo.launch(share=True)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 6: Gradio UI (Updated with Association Tab)\n",
    "# =============================================================================\n",
    "\n",
    "IVE_MEMBERS = [\"Wonyoung\", \"Yujin\", \"Gaeul\", \"Liz\", \"Leeseo\", \"Rei\"]\n",
    "\n",
    "def gradio_segment(input_image, member_name):\n",
    "    \"\"\"Gradio callback for image segmentation\"\"\"\n",
    "    if input_image is None:\n",
    "        return None, None, None, \"‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û\"\n",
    "    \n",
    "    image_bgr = cv2.cvtColor(input_image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    overlay, cutout, annotated, mask, msg = segment_member(image_bgr, member_name)\n",
    "    \n",
    "    if overlay is None:\n",
    "        return None, None, None, msg\n",
    "    \n",
    "    return annotated, overlay, cutout, msg\n",
    "\n",
    "def gradio_identify_all(input_image):\n",
    "    \"\"\"‡πÅ‡∏™‡∏î‡∏á‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà identify ‡πÑ‡∏î‡πâ\"\"\"\n",
    "    if input_image is None:\n",
    "        return None, \"‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û\"\n",
    "    \n",
    "    image_bgr = cv2.cvtColor(input_image, cv2.COLOR_RGB2BGR)\n",
    "    members = identify_all_members(image_bgr, face_analyzer, embeddings_db)\n",
    "    \n",
    "    annotated = input_image.copy()\n",
    "    info_lines = []\n",
    "    \n",
    "    for m in members:\n",
    "        x1, y1, x2, y2 = m[\"bbox\"]\n",
    "        cv2.rectangle(annotated, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        if m[\"similarity\"]:\n",
    "            label = f\"{m['name']} {m['similarity']:.2f}\"\n",
    "            info_lines.append(f\"{m['name']}: similarity={m['similarity']:.3f}\")\n",
    "        else:\n",
    "            label = m[\"name\"]\n",
    "        cv2.putText(annotated, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    return annotated, \"\\n\".join(info_lines)\n",
    "\n",
    "def gradio_associate(input_image, member_name, object_text):\n",
    "    \"\"\"Gradio callback for association (e.g., 'Wonyoung's shirt')\"\"\"\n",
    "    if input_image is None:\n",
    "        return None, None, \"‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û\"\n",
    "    \n",
    "    image_bgr = cv2.cvtColor(input_image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    annotated, object_overlay, object_mask, msg = segment_associated_object(\n",
    "        image_bgr, member_name, object_text\n",
    "    )\n",
    "    \n",
    "    if annotated is None:\n",
    "        return None, None, msg\n",
    "    \n",
    "    return annotated, object_overlay, msg\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á Gradio Interface\n",
    "with gr.Blocks(title=\"IVE Segmentation\") as demo:\n",
    "    gr.Markdown(\"# üéØ IVE Member Segmentation with SAM 3\")\n",
    "    gr.Markdown(\"‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡∏Å‡∏•‡∏∏‡πà‡∏° IVE ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å ‚Üí ‡∏£‡∏∞‡∏ö‡∏ö segment ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÉ‡∏´‡πâ\")\n",
    "    \n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem(\"üîç Segment Member\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    img_input = gr.Image(label=\"‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û\", type=\"numpy\")\n",
    "                    member_dropdown = gr.Dropdown(\n",
    "                        choices=IVE_MEMBERS,\n",
    "                        value=\"Wonyoung\",\n",
    "                        label=\"‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å\"\n",
    "                    )\n",
    "                    btn_segment = gr.Button(\"üîç Segment\", variant=\"primary\")\n",
    "                    status_text = gr.Textbox(label=\"Status\", interactive=False)\n",
    "                \n",
    "                with gr.Column(scale=2):\n",
    "                    with gr.Row():\n",
    "                        out_identified = gr.Image(label=\"Identified\")\n",
    "                        out_overlay = gr.Image(label=\"Segmented\")\n",
    "                        out_cutout = gr.Image(label=\"Cutout\")\n",
    "            \n",
    "            btn_segment.click(\n",
    "                fn=gradio_segment,\n",
    "                inputs=[img_input, member_dropdown],\n",
    "                outputs=[out_identified, out_overlay, out_cutout, status_text]\n",
    "            )\n",
    "        \n",
    "        with gr.TabItem(\"üëï Association (e.g., Wonyoung's shirt)\"):\n",
    "            gr.Markdown(\"### ‡∏´‡∏≤‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•\")\n",
    "            gr.Markdown(\"‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: `shirt`, `hair`, `pants`, `dress`, `shoes`\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    img_input_assoc = gr.Image(label=\"‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û\", type=\"numpy\")\n",
    "                    member_dropdown_assoc = gr.Dropdown(\n",
    "                        choices=IVE_MEMBERS,\n",
    "                        value=\"Wonyoung\",\n",
    "                        label=\"‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å\"\n",
    "                    )\n",
    "                    object_text_input = gr.Textbox(\n",
    "                        label=\"‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (object)\",\n",
    "                        value=\"shirt\",\n",
    "                        placeholder=\"‡πÄ‡∏ä‡πà‡∏ô: shirt, hair, pants, dress\"\n",
    "                    )\n",
    "                    btn_associate = gr.Button(\"üëï Find Object\", variant=\"primary\")\n",
    "                    status_text_assoc = gr.Textbox(label=\"Status\", interactive=False)\n",
    "                \n",
    "                with gr.Column(scale=2):\n",
    "                    with gr.Row():\n",
    "                        out_annotated_assoc = gr.Image(label=\"Annotated with ROI\")\n",
    "                        out_object_overlay = gr.Image(label=\"Object Overlay\")\n",
    "            \n",
    "            btn_associate.click(\n",
    "                fn=gradio_associate,\n",
    "                inputs=[img_input_assoc, member_dropdown_assoc, object_text_input],\n",
    "                outputs=[out_annotated_assoc, out_object_overlay, status_text_assoc]\n",
    "            )\n",
    "        \n",
    "        with gr.TabItem(\"üë• Identify All\"):\n",
    "            with gr.Row():\n",
    "                img_input_all = gr.Image(label=\"‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û\", type=\"numpy\")\n",
    "                btn_identify = gr.Button(\"üë• Identify All\", variant=\"primary\")\n",
    "            with gr.Row():\n",
    "                out_all = gr.Image(label=\"All Members\")\n",
    "                out_info = gr.Textbox(label=\"Info\", lines=8)\n",
    "            \n",
    "            btn_identify.click(\n",
    "                fn=gradio_identify_all,\n",
    "                inputs=[img_input_all],\n",
    "                outputs=[out_all, out_info]\n",
    "            )\n",
    "\n",
    "print(\"‚úÖ Gradio UI created!\")\n",
    "print(\"‡∏£‡∏±‡∏ô‡∏î‡πâ‡∏ß‡∏¢: demo.launch(share=True)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* Running on public URL: https://eec409b71b987bb98b.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://eec409b71b987bb98b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ‡∏£‡∏±‡∏ô Gradio UI\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section-7'></a>\n",
    "## Section 7: Video Inference üé¨\n",
    "\n",
    "‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÅ‡∏ö‡∏ö Frame-by-Frame ‡∏û‡∏£‡πâ‡∏≠‡∏° Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Video processing classes loaded!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 7: Video Inference\n",
    "# =============================================================================\n",
    "\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "class SimpleTracker:\n",
    "    \"\"\"Simple IoU-based tracker\"\"\"\n",
    "    \n",
    "    def __init__(self, iou_threshold=0.5, max_disappeared=5):\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.max_disappeared = max_disappeared\n",
    "        self.objects = {}\n",
    "        self.disappeared = {}\n",
    "        self.next_object_id = 0\n",
    "    \n",
    "    def compute_iou(self, box1, box2):\n",
    "        x1_1, y1_1, x2_1, y2_1 = box1\n",
    "        x1_2, y1_2, x2_2, y2_2 = box2\n",
    "        xi1 = max(x1_1, x1_2)\n",
    "        yi1 = max(y1_1, y1_2)\n",
    "        xi2 = min(x2_1, x2_2)\n",
    "        yi2 = min(y2_1, y2_2)\n",
    "        if xi2 <= xi1 or yi2 <= yi1:\n",
    "            return 0.0\n",
    "        inter_area = (xi2 - xi1) * (yi2 - yi1)\n",
    "        box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
    "        box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
    "        union_area = box1_area + box2_area - inter_area\n",
    "        return inter_area / union_area if union_area > 0 else 0.0\n",
    "    \n",
    "    def update(self, detections):\n",
    "        if len(detections) == 0:\n",
    "            for obj_id in list(self.disappeared.keys()):\n",
    "                self.disappeared[obj_id] += 1\n",
    "                if self.disappeared[obj_id] > self.max_disappeared:\n",
    "                    del self.objects[obj_id]\n",
    "                    del self.disappeared[obj_id]\n",
    "            return self.objects\n",
    "        \n",
    "        if len(self.objects) == 0:\n",
    "            for det in detections:\n",
    "                self.objects[self.next_object_id] = det\n",
    "                self.disappeared[self.next_object_id] = 0\n",
    "                self.next_object_id += 1\n",
    "        else:\n",
    "            object_ids = list(self.objects.keys())\n",
    "            object_bboxes = [self.objects[oid]['bbox'] for oid in object_ids]\n",
    "            detection_bboxes = [d['bbox'] for d in detections]\n",
    "            \n",
    "            iou_matrix = np.zeros((len(object_ids), len(detections)))\n",
    "            for i, obj_box in enumerate(object_bboxes):\n",
    "                for j, det_box in enumerate(detection_bboxes):\n",
    "                    iou_matrix[i, j] = self.compute_iou(obj_box, det_box)\n",
    "            \n",
    "            matched_object_ids = set()\n",
    "            matched_detection_indices = set()\n",
    "            \n",
    "            while True:\n",
    "                max_iou = np.max(iou_matrix)\n",
    "                if max_iou < self.iou_threshold:\n",
    "                    break\n",
    "                max_idx = np.unravel_index(np.argmax(iou_matrix), iou_matrix.shape)\n",
    "                obj_idx, det_idx = max_idx\n",
    "                object_id = object_ids[obj_idx]\n",
    "                self.objects[object_id] = detections[det_idx]\n",
    "                self.disappeared[object_id] = 0\n",
    "                matched_object_ids.add(object_id)\n",
    "                matched_detection_indices.add(det_idx)\n",
    "                iou_matrix[obj_idx, :] = -1\n",
    "                iou_matrix[:, det_idx] = -1\n",
    "            \n",
    "            for object_id in object_ids:\n",
    "                if object_id not in matched_object_ids:\n",
    "                    self.disappeared[object_id] += 1\n",
    "                    if self.disappeared[object_id] > self.max_disappeared:\n",
    "                        del self.objects[object_id]\n",
    "                        del self.disappeared[object_id]\n",
    "            \n",
    "            for i, detection in enumerate(detections):\n",
    "                if i not in matched_detection_indices:\n",
    "                    self.objects[self.next_object_id] = detection\n",
    "                    self.disappeared[self.next_object_id] = 0\n",
    "                    self.next_object_id += 1\n",
    "        \n",
    "        return self.objects\n",
    "\n",
    "class TemporalSmoother:\n",
    "    \"\"\"Temporal smoothing for masks\"\"\"\n",
    "    \n",
    "    def __init__(self, window_size=5):\n",
    "        self.window_size = window_size\n",
    "        self.mask_history = deque(maxlen=window_size)\n",
    "    \n",
    "    def update(self, mask):\n",
    "        mask_float = mask.astype(np.float32)\n",
    "        self.mask_history.append(mask_float)\n",
    "        if len(self.mask_history) > 0:\n",
    "            smoothed = np.mean(self.mask_history, axis=0)\n",
    "            return (smoothed > 0.5).astype(np.uint8)\n",
    "        return mask\n",
    "    \n",
    "    def reset(self):\n",
    "        self.mask_history.clear()\n",
    "\n",
    "print(\"‚úÖ Video processing classes loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Video processing function ready!\n"
     ]
    }
   ],
   "source": [
    "def process_video(input_path, output_path, target_member, frame_sampling=5):\n",
    "    \"\"\"\n",
    "    ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ frame-by-frame\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Cannot open video: {input_path}\")\n",
    "    \n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    print(f\"üìπ Video: {width}x{height} @ {fps}fps, {total_frames} frames\")\n",
    "    \n",
    "    os.makedirs(os.path.dirname(output_path) or \".\", exist_ok=True)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps / frame_sampling, (width, height))\n",
    "    \n",
    "    tracker = SimpleTracker(iou_threshold=0.5, max_disappeared=5)\n",
    "    smoother = TemporalSmoother(window_size=5)\n",
    "    \n",
    "    frame_idx = 0\n",
    "    processed_count = 0\n",
    "    \n",
    "    with tqdm(total=total_frames, desc=\"Processing\") as pbar:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            if frame_idx % frame_sampling == 0:\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                # Identify members\n",
    "                members = identify_all_members(frame, face_analyzer, embeddings_db)\n",
    "                \n",
    "                # Find target member\n",
    "                target_detections = [m for m in members if m['name'] == target_member]\n",
    "                \n",
    "                # Update tracker\n",
    "                tracked = tracker.update(target_detections)\n",
    "                \n",
    "                # Process each tracked object\n",
    "                output_frame = frame_rgb.copy()\n",
    "                \n",
    "                for obj_id, obj_data in tracked.items():\n",
    "                    bbox = obj_data['bbox']\n",
    "                    \n",
    "                    # Segment\n",
    "                    image_pil = Image.fromarray(frame_rgb)\n",
    "                    body_bbox = face_to_body_bbox(np.array(bbox), (height, width))\n",
    "                    mask = segment_by_box(image_pil, body_bbox.tolist())\n",
    "                    mask = clean_mask(mask, kernel_size=5)  # Clean up mask\n",
    "                    \n",
    "                    # Temporal smoothing\n",
    "                    smoothed_mask = smoother.update(mask)\n",
    "                    \n",
    "                    # Visualization\n",
    "                    color = (255, 105, 180)\n",
    "                    output_frame = create_overlay(output_frame, smoothed_mask, color, 0.5)\n",
    "                    \n",
    "                    # Draw bbox\n",
    "                    x1, y1, x2, y2 = bbox\n",
    "                    cv2.rectangle(output_frame, (x1, y1), (x2, y2), color, 2)\n",
    "                    cv2.putText(output_frame, target_member, (x1, y1-10), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "                \n",
    "                # Write output\n",
    "                output_bgr = cv2.cvtColor(output_frame, cv2.COLOR_RGB2BGR)\n",
    "                out.write(output_bgr)\n",
    "                processed_count += 1\n",
    "            \n",
    "            frame_idx += 1\n",
    "            pbar.update(1)\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"\\n‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• {processed_count} frames\")\n",
    "    print(f\"   ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏µ‡πà: {output_path}\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "print(\"‚úÖ Video processing function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìπ Video: 1920x1080 @ 30.0fps, 909 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/909 [00:00<?, ?it/s]/root/SEGMENTATION_IVE/.venv/lib/python3.10/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "Processing:   1%|          | 6/909 [00:00<00:19, 45.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Gaeul: similarity=0.6917\n",
      "   ‚úÖ Leeseo: similarity=0.5648\n",
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.5449\n",
      "   ‚úÖ Gaeul: similarity=0.6823\n",
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.6790\n",
      "   ‚úÖ Gaeul: similarity=0.6758\n",
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.6872\n",
      "   ‚úÖ Gaeul: similarity=0.6659\n",
      "   ‚úÖ Wonyoung: similarity=0.4583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|‚ñè         | 16/909 [00:00<00:19, 46.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Gaeul: similarity=0.6773\n",
      "   ‚úÖ Leeseo: similarity=0.6796\n",
      "   ‚úÖ Wonyoung: similarity=0.4636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|‚ñè         | 21/909 [00:00<00:21, 41.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Gaeul: similarity=0.6503\n",
      "   ‚úÖ Leeseo: similarity=0.6920\n",
      "   ‚úÖ Wonyoung: similarity=0.4900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|‚ñé         | 26/909 [00:00<00:23, 38.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Gaeul: similarity=0.5894\n",
      "   ‚úÖ Leeseo: similarity=0.6985\n",
      "   ‚úÖ Wonyoung: similarity=0.5076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|‚ñé         | 31/909 [00:00<00:24, 36.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Gaeul: similarity=0.6212\n",
      "   ‚úÖ Leeseo: similarity=0.7010\n",
      "   ‚úÖ Wonyoung: similarity=0.5019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|‚ñç         | 36/909 [00:00<00:24, 35.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.6813\n",
      "   ‚úÖ Gaeul: similarity=0.6372\n",
      "   ‚úÖ Wonyoung: similarity=0.4701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   5%|‚ñç         | 41/909 [00:01<00:24, 35.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.6553\n",
      "   ‚úÖ Gaeul: similarity=0.6112\n",
      "   ‚úÖ Wonyoung: similarity=0.5366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   5%|‚ñå         | 46/909 [00:01<00:24, 34.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7436\n",
      "   ‚úÖ Wonyoung: similarity=0.5553\n",
      "   ‚úÖ Gaeul: similarity=0.6175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   6%|‚ñå         | 51/909 [00:01<00:24, 34.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7337\n",
      "   ‚úÖ Wonyoung: similarity=0.5848\n",
      "   ‚úÖ Gaeul: similarity=0.5860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   6%|‚ñå         | 56/909 [00:01<00:24, 34.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.6624\n",
      "   ‚úÖ Wonyoung: similarity=0.5753\n",
      "   ‚úÖ Gaeul: similarity=0.6063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   7%|‚ñã         | 61/909 [00:01<00:24, 34.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5616\n",
      "   ‚úÖ Leeseo: similarity=0.6710\n",
      "   ‚úÖ Liz: similarity=0.6871\n",
      "   ‚úÖ Gaeul: similarity=0.5338\n",
      "   ‚úÖ Wonyoung: similarity=0.6004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   8%|‚ñä         | 71/909 [00:02<00:34, 24.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5686\n",
      "   ‚úÖ Liz: similarity=0.5932\n",
      "   ‚úÖ Leeseo: similarity=0.6882\n",
      "   ‚úÖ Gaeul: similarity=0.5609\n",
      "   ‚úÖ Yujin: similarity=0.5427\n",
      "   ‚úÖ Wonyoung: similarity=0.5903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   8%|‚ñä         | 76/909 [00:02<00:36, 22.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5563\n",
      "   ‚úÖ Liz: similarity=0.6305\n",
      "   ‚úÖ Leeseo: similarity=0.6942\n",
      "   ‚úÖ Gaeul: similarity=0.5880\n",
      "   ‚úÖ Yujin: similarity=0.5593\n",
      "   ‚úÖ Wonyoung: similarity=0.5754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   9%|‚ñâ         | 81/909 [00:02<00:38, 21.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.6996\n",
      "   ‚úÖ Rei: similarity=0.5670\n",
      "   ‚úÖ Liz: similarity=0.6495\n",
      "   ‚úÖ Gaeul: similarity=0.5781\n",
      "   ‚úÖ Yujin: similarity=0.5499\n",
      "   ‚úÖ Wonyoung: similarity=0.5726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   9%|‚ñâ         | 86/909 [00:02<00:38, 21.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5437\n",
      "   ‚úÖ Liz: similarity=0.6400\n",
      "   ‚úÖ Leeseo: similarity=0.6800\n",
      "   ‚úÖ Yujin: similarity=0.5880\n",
      "   ‚úÖ Gaeul: similarity=0.6308\n",
      "   ‚úÖ Wonyoung: similarity=0.5062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  10%|‚ñà         | 91/909 [00:03<00:35, 23.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5046\n",
      "   ‚úÖ Liz: similarity=0.6106\n",
      "   ‚úÖ Leeseo: similarity=0.7045\n",
      "   ‚úÖ Gaeul: similarity=0.6000\n",
      "   ‚úÖ Yujin: similarity=0.5377\n",
      "   ‚úÖ Wonyoung: similarity=0.5033\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7030\n",
      "   ‚úÖ Rei: similarity=0.5859\n",
      "   ‚úÖ Liz: similarity=0.6888\n",
      "   ‚úÖ Gaeul: similarity=0.6425\n",
      "   ‚úÖ Yujin: similarity=0.6482\n",
      "   ‚úÖ Wonyoung: similarity=0.5185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  11%|‚ñà         | 101/909 [00:03<00:31, 25.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7284\n",
      "   ‚úÖ Liz: similarity=0.6572\n",
      "   ‚úÖ Rei: similarity=0.5885\n",
      "   ‚úÖ Gaeul: similarity=0.6101\n",
      "   ‚úÖ Yujin: similarity=0.6237\n",
      "   ‚úÖ Wonyoung: similarity=0.4964\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5887\n",
      "   ‚úÖ Leeseo: similarity=0.7542\n",
      "   ‚úÖ Liz: similarity=0.6344\n",
      "   ‚úÖ Gaeul: similarity=0.5966\n",
      "   ‚úÖ Wonyoung: similarity=0.5877\n",
      "   ‚úÖ Yujin: similarity=0.5380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  12%|‚ñà‚ñè        | 111/909 [00:03<00:29, 27.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5926\n",
      "   ‚úÖ Liz: similarity=0.6544\n",
      "   ‚úÖ Leeseo: similarity=0.7477\n",
      "   ‚úÖ Gaeul: similarity=0.5667\n",
      "   ‚úÖ Wonyoung: similarity=0.4932\n",
      "   ‚úÖ Yujin: similarity=0.5178\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.6225\n",
      "   ‚úÖ Liz: similarity=0.6035\n",
      "   ‚úÖ Leeseo: similarity=0.7619\n",
      "   ‚úÖ Wonyoung: similarity=0.5363\n",
      "   ‚úÖ Yujin: similarity=0.5789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  13%|‚ñà‚ñé        | 121/909 [00:04<00:27, 28.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.6303\n",
      "   ‚úÖ Liz: similarity=0.5904\n",
      "   ‚úÖ Leeseo: similarity=0.7275\n",
      "   ‚úÖ Wonyoung: similarity=0.5126\n",
      "   ‚úÖ Yujin: similarity=0.6268\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.6197\n",
      "   ‚úÖ Liz: similarity=0.6355\n",
      "   ‚úÖ Leeseo: similarity=0.7041\n",
      "   ‚úÖ Wonyoung: similarity=0.5530\n",
      "   ‚úÖ Yujin: similarity=0.6119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  14%|‚ñà‚ñç        | 131/909 [00:04<00:27, 28.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Liz: similarity=0.6397\n",
      "   ‚úÖ Rei: similarity=0.6006\n",
      "   ‚úÖ Leeseo: similarity=0.7382\n",
      "   ‚úÖ Yujin: similarity=0.4599\n",
      "   ‚úÖ Wonyoung: similarity=0.5014\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Liz: similarity=0.6202\n",
      "   ‚úÖ Rei: similarity=0.5945\n",
      "   ‚úÖ Leeseo: similarity=0.6727\n",
      "   ‚úÖ Yujin: similarity=0.5697\n",
      "   ‚úÖ Wonyoung: similarity=0.5537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  16%|‚ñà‚ñå        | 141/909 [00:04<00:26, 28.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7198\n",
      "   ‚úÖ Liz: similarity=0.6277\n",
      "   ‚úÖ Rei: similarity=0.6195\n",
      "   ‚úÖ Yujin: similarity=0.6053\n",
      "   ‚úÖ Wonyoung: similarity=0.5749\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.6864\n",
      "   ‚úÖ Liz: similarity=0.6224\n",
      "   ‚úÖ Rei: similarity=0.6035\n",
      "   ‚úÖ Yujin: similarity=0.6315\n",
      "   ‚úÖ Wonyoung: similarity=0.5628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  17%|‚ñà‚ñã        | 151/909 [00:05<00:25, 29.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Liz: similarity=0.6524\n",
      "   ‚úÖ Leeseo: similarity=0.6556\n",
      "   ‚úÖ Rei: similarity=0.6370\n",
      "   ‚úÖ Yujin: similarity=0.6360\n",
      "   ‚úÖ Wonyoung: similarity=0.4905\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Liz: similarity=0.6585\n",
      "   ‚úÖ Leeseo: similarity=0.7054\n",
      "   ‚úÖ Rei: similarity=0.6405\n",
      "   ‚úÖ Yujin: similarity=0.6416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  18%|‚ñà‚ñä        | 161/909 [00:05<00:25, 29.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7147\n",
      "   ‚úÖ Liz: similarity=0.6466\n",
      "   ‚úÖ Rei: similarity=0.6392\n",
      "   ‚úÖ Yujin: similarity=0.6404\n",
      "   ‚úÖ Wonyoung: similarity=0.5856\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7671\n",
      "   ‚úÖ Liz: similarity=0.6578\n",
      "   ‚úÖ Rei: similarity=0.6343\n",
      "   ‚úÖ Yujin: similarity=0.6331\n",
      "   ‚úÖ Wonyoung: similarity=0.5932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  19%|‚ñà‚ñâ        | 171/909 [00:05<00:25, 29.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7483\n",
      "   ‚úÖ Liz: similarity=0.6613\n",
      "   ‚úÖ Rei: similarity=0.6420\n",
      "   ‚úÖ Wonyoung: similarity=0.4907\n",
      "   ‚úÖ Yujin: similarity=0.6361\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7846\n",
      "   ‚úÖ Liz: similarity=0.6645\n",
      "   ‚úÖ Rei: similarity=0.6437\n",
      "   ‚úÖ Yujin: similarity=0.6218\n",
      "   ‚úÖ Wonyoung: similarity=0.4565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  20%|‚ñà‚ñâ        | 181/909 [00:06<00:24, 29.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7677\n",
      "   ‚úÖ Liz: similarity=0.6527\n",
      "   ‚úÖ Rei: similarity=0.6071\n",
      "   ‚úÖ Yujin: similarity=0.6155\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7553\n",
      "   ‚úÖ Liz: similarity=0.6485\n",
      "   ‚úÖ Rei: similarity=0.6109\n",
      "   ‚úÖ Yujin: similarity=0.6042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  21%|‚ñà‚ñà        | 191/909 [00:06<00:24, 29.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7553\n",
      "   ‚úÖ Rei: similarity=0.6346\n",
      "   ‚úÖ Liz: similarity=0.6677\n",
      "   ‚úÖ Yujin: similarity=0.5954\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Liz: similarity=0.6382\n",
      "   ‚úÖ Leeseo: similarity=0.7032\n",
      "   ‚úÖ Rei: similarity=0.6266\n",
      "   ‚úÖ Yujin: similarity=0.5663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  22%|‚ñà‚ñà‚ñè       | 201/909 [00:06<00:23, 29.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Liz: similarity=0.6061\n",
      "   ‚úÖ Leeseo: similarity=0.6590\n",
      "   ‚úÖ Rei: similarity=0.6551\n",
      "   ‚úÖ Yujin: similarity=0.5602\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.6361\n",
      "   ‚úÖ Leeseo: similarity=0.6624\n",
      "   ‚úÖ Liz: similarity=0.5594\n",
      "   ‚úÖ Yujin: similarity=0.5593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  24%|‚ñà‚ñà‚ñç       | 216/909 [00:07<00:19, 35.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.6933\n",
      "   ‚úÖ Rei: similarity=0.6361\n",
      "   ‚úÖ Liz: similarity=0.6366\n",
      "   ‚úÖ Yujin: similarity=0.5797\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7058\n",
      "   ‚úÖ Liz: similarity=0.6534\n",
      "   ‚úÖ Rei: similarity=0.6043\n",
      "   ‚úÖ Gaeul: similarity=0.5725\n",
      "   ‚úÖ Yujin: similarity=0.6027\n",
      "   ‚úÖ Wonyoung: similarity=0.5264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  24%|‚ñà‚ñà‚ñç       | 221/909 [00:07<00:20, 33.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.6798\n",
      "   ‚úÖ Liz: similarity=0.6359\n",
      "   ‚úÖ Rei: similarity=0.5995\n",
      "   ‚úÖ Gaeul: similarity=0.6182\n",
      "   ‚úÖ Yujin: similarity=0.6205\n",
      "   ‚úÖ Wonyoung: similarity=0.6310\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7532\n",
      "   ‚úÖ Liz: similarity=0.7102\n",
      "   ‚úÖ Gaeul: similarity=0.6351\n",
      "   ‚úÖ Rei: similarity=0.6024\n",
      "   ‚úÖ Yujin: similarity=0.6607\n",
      "   ‚úÖ Wonyoung: similarity=0.5885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  25%|‚ñà‚ñà‚ñå       | 231/909 [00:07<00:21, 31.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7760\n",
      "   ‚úÖ Liz: similarity=0.6421\n",
      "   ‚úÖ Gaeul: similarity=0.6329\n",
      "   ‚úÖ Rei: similarity=0.5939\n",
      "   ‚úÖ Yujin: similarity=0.6787\n",
      "   ‚úÖ Wonyoung: similarity=0.6490\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7722\n",
      "   ‚úÖ Liz: similarity=0.6715\n",
      "   ‚úÖ Rei: similarity=0.5874\n",
      "   ‚úÖ Gaeul: similarity=0.6118\n",
      "   ‚úÖ Yujin: similarity=0.6918\n",
      "   ‚úÖ Wonyoung: similarity=0.6362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  27%|‚ñà‚ñà‚ñã       | 241/909 [00:08<00:22, 29.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7845\n",
      "   ‚úÖ Liz: similarity=0.6621\n",
      "   ‚úÖ Gaeul: similarity=0.6390\n",
      "   ‚úÖ Rei: similarity=0.5796\n",
      "   ‚úÖ Yujin: similarity=0.6785\n",
      "   ‚úÖ Wonyoung: similarity=0.6478\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7689\n",
      "   ‚úÖ Gaeul: similarity=0.6189\n",
      "   ‚úÖ Liz: similarity=0.6653\n",
      "   ‚úÖ Rei: similarity=0.6123\n",
      "   ‚úÖ Yujin: similarity=0.6441\n",
      "   ‚úÖ Wonyoung: similarity=0.6742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  28%|‚ñà‚ñà‚ñä       | 251/909 [00:08<00:22, 29.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7079\n",
      "   ‚úÖ Gaeul: similarity=0.6428\n",
      "   ‚úÖ Liz: similarity=0.6721\n",
      "   ‚úÖ Rei: similarity=0.6244\n",
      "   ‚úÖ Wonyoung: similarity=0.6653\n",
      "   ‚úÖ Yujin: similarity=0.6725\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7464\n",
      "   ‚úÖ Gaeul: similarity=0.6561\n",
      "   ‚úÖ Rei: similarity=0.5724\n",
      "   ‚úÖ Liz: similarity=0.6497\n",
      "   ‚úÖ Wonyoung: similarity=0.6343\n",
      "   ‚úÖ Yujin: similarity=0.6546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  29%|‚ñà‚ñà‚ñä       | 261/909 [00:08<00:22, 29.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7648\n",
      "   ‚úÖ Gaeul: similarity=0.6305\n",
      "   ‚úÖ Rei: similarity=0.5949\n",
      "   ‚úÖ Liz: similarity=0.6564\n",
      "   ‚úÖ Yujin: similarity=0.6447\n",
      "   ‚úÖ Wonyoung: similarity=0.6348\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7224\n",
      "   ‚úÖ Gaeul: similarity=0.6617\n",
      "   ‚úÖ Rei: similarity=0.6409\n",
      "   ‚úÖ Liz: similarity=0.6179\n",
      "   ‚úÖ Yujin: similarity=0.6982\n",
      "   ‚úÖ Wonyoung: similarity=0.6614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  30%|‚ñà‚ñà‚ñâ       | 271/909 [00:09<00:21, 29.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7313\n",
      "   ‚úÖ Gaeul: similarity=0.6434\n",
      "   ‚úÖ Rei: similarity=0.6211\n",
      "   ‚úÖ Liz: similarity=0.6051\n",
      "   ‚úÖ Yujin: similarity=0.6655\n",
      "   ‚úÖ Wonyoung: similarity=0.6338\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7614\n",
      "   ‚úÖ Gaeul: similarity=0.6694\n",
      "   ‚úÖ Rei: similarity=0.6207\n",
      "   ‚úÖ Liz: similarity=0.7012\n",
      "   ‚úÖ Wonyoung: similarity=0.7028\n",
      "   ‚úÖ Yujin: similarity=0.6684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  31%|‚ñà‚ñà‚ñà       | 281/909 [00:09<00:21, 29.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Gaeul: similarity=0.6341\n",
      "   ‚úÖ Leeseo: similarity=0.7359\n",
      "   ‚úÖ Liz: similarity=0.7036\n",
      "   ‚úÖ Rei: similarity=0.6438\n",
      "   ‚úÖ Wonyoung: similarity=0.6745\n",
      "   ‚úÖ Yujin: similarity=0.6682\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Gaeul: similarity=0.6040\n",
      "   ‚úÖ Rei: similarity=0.6103\n",
      "   ‚úÖ Liz: similarity=0.7091\n",
      "   ‚úÖ Leeseo: similarity=0.7391\n",
      "   ‚úÖ Wonyoung: similarity=0.6983\n",
      "   ‚úÖ Yujin: similarity=0.6740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  32%|‚ñà‚ñà‚ñà‚ñè      | 291/909 [00:09<00:21, 29.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.6131\n",
      "   ‚úÖ Gaeul: similarity=0.6277\n",
      "   ‚úÖ Leeseo: similarity=0.7433\n",
      "   ‚úÖ Liz: similarity=0.7071\n",
      "   ‚úÖ Wonyoung: similarity=0.6745\n",
      "   ‚úÖ Yujin: similarity=0.6369\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.6370\n",
      "   ‚úÖ Leeseo: similarity=0.7465\n",
      "   ‚úÖ Liz: similarity=0.6959\n",
      "   ‚úÖ Gaeul: similarity=0.6211\n",
      "   ‚úÖ Wonyoung: similarity=0.6664\n",
      "   ‚úÖ Yujin: similarity=0.7193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  33%|‚ñà‚ñà‚ñà‚ñé      | 301/909 [00:10<00:20, 29.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.6452\n",
      "   ‚úÖ Leeseo: similarity=0.7468\n",
      "   ‚úÖ Liz: similarity=0.6831\n",
      "   ‚úÖ Gaeul: similarity=0.6627\n",
      "   ‚úÖ Wonyoung: similarity=0.6664\n",
      "   ‚úÖ Yujin: similarity=0.6507\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7203\n",
      "   ‚úÖ Rei: similarity=0.6480\n",
      "   ‚úÖ Liz: similarity=0.6203\n",
      "   ‚úÖ Gaeul: similarity=0.6392\n",
      "   ‚úÖ Yujin: similarity=0.6872\n",
      "   ‚úÖ Wonyoung: similarity=0.6847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  34%|‚ñà‚ñà‚ñà‚ñç      | 311/909 [00:10<00:20, 29.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.6247\n",
      "   ‚úÖ Liz: similarity=0.6932\n",
      "   ‚úÖ Gaeul: similarity=0.6189\n",
      "   ‚úÖ Leeseo: similarity=0.6964\n",
      "   ‚úÖ Yujin: similarity=0.6991\n",
      "   ‚úÖ Wonyoung: similarity=0.7065\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.6504\n",
      "   ‚úÖ Leeseo: similarity=0.6549\n",
      "   ‚úÖ Liz: similarity=0.6411\n",
      "   ‚úÖ Gaeul: similarity=0.6360\n",
      "   ‚úÖ Yujin: similarity=0.6647\n",
      "   ‚úÖ Wonyoung: similarity=0.7156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  35%|‚ñà‚ñà‚ñà‚ñå      | 321/909 [00:10<00:20, 29.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.6275\n",
      "   ‚úÖ Leeseo: similarity=0.6542\n",
      "   ‚úÖ Liz: similarity=0.6026\n",
      "   ‚úÖ Gaeul: similarity=0.5912\n",
      "   ‚úÖ Yujin: similarity=0.7010\n",
      "   ‚úÖ Wonyoung: similarity=0.7206\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.6103\n",
      "   ‚úÖ Liz: similarity=0.6435\n",
      "   ‚úÖ Leeseo: similarity=0.6909\n",
      "   ‚úÖ Gaeul: similarity=0.6068\n",
      "   ‚úÖ Yujin: similarity=0.7029\n",
      "   ‚úÖ Wonyoung: similarity=0.7266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  36%|‚ñà‚ñà‚ñà‚ñã      | 331/909 [00:11<00:19, 29.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.6293\n",
      "   ‚úÖ Liz: similarity=0.6570\n",
      "   ‚úÖ Leeseo: similarity=0.6956\n",
      "   ‚úÖ Gaeul: similarity=0.6571\n",
      "   ‚úÖ Wonyoung: similarity=0.6962\n",
      "   ‚úÖ Yujin: similarity=0.6927\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.6014\n",
      "   ‚úÖ Liz: similarity=0.6572\n",
      "   ‚úÖ Gaeul: similarity=0.6400\n",
      "   ‚úÖ Leeseo: similarity=0.6673\n",
      "   ‚úÖ Wonyoung: similarity=0.6638\n",
      "   ‚úÖ Yujin: similarity=0.6857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  38%|‚ñà‚ñà‚ñà‚ñä      | 341/909 [00:11<00:19, 29.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5723\n",
      "   ‚úÖ Liz: similarity=0.6466\n",
      "   ‚úÖ Leeseo: similarity=0.6628\n",
      "   ‚úÖ Gaeul: similarity=0.5950\n",
      "   ‚úÖ Yujin: similarity=0.7035\n",
      "   ‚úÖ Wonyoung: similarity=0.6253\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5714\n",
      "   ‚úÖ Liz: similarity=0.6509\n",
      "   ‚úÖ Leeseo: similarity=0.6792\n",
      "   ‚úÖ Gaeul: similarity=0.5728\n",
      "   ‚úÖ Wonyoung: similarity=0.6437\n",
      "   ‚úÖ Yujin: similarity=0.6674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  39%|‚ñà‚ñà‚ñà‚ñä      | 351/909 [00:11<00:19, 29.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5675\n",
      "   ‚úÖ Liz: similarity=0.6033\n",
      "   ‚úÖ Gaeul: similarity=0.5856\n",
      "   ‚úÖ Leeseo: similarity=0.6791\n",
      "   ‚úÖ Wonyoung: similarity=0.6449\n",
      "   ‚úÖ Yujin: similarity=0.6433\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5749\n",
      "   ‚úÖ Liz: similarity=0.5937\n",
      "   ‚úÖ Leeseo: similarity=0.6857\n",
      "   ‚úÖ Gaeul: similarity=0.6034\n",
      "   ‚úÖ Wonyoung: similarity=0.6531\n",
      "   ‚úÖ Yujin: similarity=0.6642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  40%|‚ñà‚ñà‚ñà‚ñâ      | 361/909 [00:12<00:18, 29.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.6118\n",
      "   ‚úÖ Liz: similarity=0.6304\n",
      "   ‚úÖ Gaeul: similarity=0.5949\n",
      "   ‚úÖ Leeseo: similarity=0.7125\n",
      "   ‚úÖ Wonyoung: similarity=0.5983\n",
      "   ‚úÖ Yujin: similarity=0.6543\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.6022\n",
      "   ‚úÖ Liz: similarity=0.6395\n",
      "   ‚úÖ Leeseo: similarity=0.6976\n",
      "   ‚úÖ Gaeul: similarity=0.5879\n",
      "   ‚úÖ Wonyoung: similarity=0.6069\n",
      "   ‚úÖ Yujin: similarity=0.5965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  41%|‚ñà‚ñà‚ñà‚ñà      | 371/909 [00:12<00:18, 29.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5920\n",
      "   ‚úÖ Gaeul: similarity=0.5728\n",
      "   ‚úÖ Liz: similarity=0.6502\n",
      "   ‚úÖ Leeseo: similarity=0.6208\n",
      "   ‚úÖ Yujin: similarity=0.6404\n",
      "   ‚úÖ Wonyoung: similarity=0.6529\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.6410\n",
      "   ‚úÖ Rei: similarity=0.6101\n",
      "   ‚úÖ Liz: similarity=0.5831\n",
      "   ‚úÖ Gaeul: similarity=0.5824\n",
      "   ‚úÖ Yujin: similarity=0.6223\n",
      "   ‚úÖ Wonyoung: similarity=0.5780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 381/909 [00:12<00:18, 28.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5958\n",
      "   ‚úÖ Gaeul: similarity=0.5849\n",
      "   ‚úÖ Liz: similarity=0.6339\n",
      "   ‚úÖ Leeseo: similarity=0.6546\n",
      "   ‚úÖ Yujin: similarity=0.6299\n",
      "   ‚úÖ Wonyoung: similarity=0.4906\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7088\n",
      "   ‚úÖ Rei: similarity=0.5875\n",
      "   ‚úÖ Liz: similarity=0.6089\n",
      "   ‚úÖ Gaeul: similarity=0.5836\n",
      "   ‚úÖ Yujin: similarity=0.6392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 391/909 [00:13<00:17, 28.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7303\n",
      "   ‚úÖ Gaeul: similarity=0.6445\n",
      "   ‚úÖ Liz: similarity=0.5726\n",
      "   ‚úÖ Rei: similarity=0.6178\n",
      "   ‚úÖ Yujin: similarity=0.5788\n",
      "   ‚úÖ Wonyoung: similarity=0.5095\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7042\n",
      "   ‚úÖ Rei: similarity=0.6446\n",
      "   ‚úÖ Liz: similarity=0.4838\n",
      "   ‚úÖ Gaeul: similarity=0.6023\n",
      "   ‚úÖ Yujin: similarity=0.5721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 401/909 [00:13<00:17, 29.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7197\n",
      "   ‚úÖ Rei: similarity=0.6654\n",
      "   ‚úÖ Liz: similarity=0.5042\n",
      "   ‚úÖ Gaeul: similarity=0.6411\n",
      "   ‚úÖ Yujin: similarity=0.6243\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.6971\n",
      "   ‚úÖ Rei: similarity=0.6215\n",
      "   ‚úÖ Liz: similarity=0.5622\n",
      "   ‚úÖ Gaeul: similarity=0.5899\n",
      "   ‚úÖ Yujin: similarity=0.6132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 411/909 [00:13<00:16, 29.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7467\n",
      "   ‚úÖ Liz: similarity=0.5699\n",
      "   ‚úÖ Gaeul: similarity=0.5781\n",
      "   ‚úÖ Rei: similarity=0.6139\n",
      "   ‚úÖ Yujin: similarity=0.6320\n",
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 436/909 [00:14<00:06, 69.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 482/909 [00:14<00:03, 133.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Liz: similarity=0.6296\n",
      "   ‚úÖ Gaeul: similarity=0.5491\n",
      "   ‚úÖ Leeseo: similarity=0.7539\n",
      "   ‚úÖ Rei: similarity=0.6293\n",
      "   ‚úÖ Yujin: similarity=0.6075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 497/909 [00:14<00:04, 83.19it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Liz: similarity=0.6383\n",
      "   ‚úÖ Rei: similarity=0.5549\n",
      "   ‚úÖ Leeseo: similarity=0.7210\n",
      "   ‚úÖ Gaeul: similarity=0.5245\n",
      "   ‚úÖ Yujin: similarity=0.6291\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5557\n",
      "   ‚úÖ Leeseo: similarity=0.7014\n",
      "   ‚úÖ Liz: similarity=0.6158\n",
      "   ‚úÖ Wonyoung: similarity=0.4752\n",
      "   ‚úÖ Yujin: similarity=0.6219\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5718\n",
      "   ‚úÖ Liz: similarity=0.6487\n",
      "   ‚úÖ Leeseo: similarity=0.6887\n",
      "   ‚úÖ Yujin: similarity=0.5900\n",
      "   ‚úÖ Wonyoung: similarity=0.5038\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.6054\n",
      "   ‚úÖ Liz: similarity=0.6403\n",
      "   ‚úÖ Leeseo: similarity=0.7070\n",
      "   ‚úÖ Wonyoung: similarity=0.5401\n",
      "   ‚úÖ Yujin: similarity=0.6037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 509/909 [00:15<00:06, 63.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.6055\n",
      "   ‚úÖ Liz: similarity=0.6259\n",
      "   ‚úÖ Leeseo: similarity=0.6899\n",
      "   ‚úÖ Gaeul: similarity=0.4695\n",
      "   ‚úÖ Yujin: similarity=0.6020\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5689\n",
      "   ‚úÖ Leeseo: similarity=0.7063\n",
      "   ‚úÖ Liz: similarity=0.6161\n",
      "   ‚úÖ Yujin: similarity=0.6031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 519/909 [00:15<00:07, 50.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5828\n",
      "   ‚úÖ Leeseo: similarity=0.7024\n",
      "   ‚úÖ Liz: similarity=0.6406\n",
      "   ‚úÖ Gaeul: similarity=0.4564\n",
      "   ‚úÖ Yujin: similarity=0.6123\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7060\n",
      "   ‚úÖ Rei: similarity=0.6024\n",
      "   ‚úÖ Liz: similarity=0.6668\n",
      "   ‚úÖ Yujin: similarity=0.6093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 533/909 [00:15<00:09, 39.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.6959\n",
      "   ‚úÖ Rei: similarity=0.5996\n",
      "   ‚úÖ Liz: similarity=0.6740\n",
      "   ‚úÖ Yujin: similarity=0.6042\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.6047\n",
      "   ‚úÖ Leeseo: similarity=0.6088\n",
      "   ‚úÖ Liz: similarity=0.6782\n",
      "   ‚úÖ Yujin: similarity=0.6405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 547/909 [00:16<00:08, 42.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 5 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.6113\n",
      "   ‚úÖ Liz: similarity=0.6562\n",
      "   ‚úÖ Leeseo: similarity=0.6457\n",
      "   ‚úÖ Yujin: similarity=0.6313\n",
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Gaeul: similarity=0.6340\n",
      "   ‚úÖ Leeseo: similarity=0.7314\n",
      "   ‚úÖ Wonyoung: similarity=0.6235\n",
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7184\n",
      "   ‚úÖ Gaeul: similarity=0.6131\n",
      "   ‚úÖ Wonyoung: similarity=0.6049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 557/909 [00:16<00:08, 39.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7217\n",
      "   ‚úÖ Gaeul: similarity=0.6278\n",
      "   ‚úÖ Wonyoung: similarity=0.6023\n",
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7377\n",
      "   ‚úÖ Gaeul: similarity=0.6575\n",
      "   ‚úÖ Wonyoung: similarity=0.5942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 566/909 [00:16<00:09, 35.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7231\n",
      "   ‚úÖ Gaeul: similarity=0.6584\n",
      "   ‚úÖ Wonyoung: similarity=0.5794\n",
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.6989\n",
      "   ‚úÖ Gaeul: similarity=0.6469\n",
      "   ‚úÖ Wonyoung: similarity=0.5662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 576/909 [00:17<00:09, 35.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.6999\n",
      "   ‚úÖ Gaeul: similarity=0.6412\n",
      "   ‚úÖ Wonyoung: similarity=0.6372\n",
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Gaeul: similarity=0.6575\n",
      "   ‚úÖ Leeseo: similarity=0.7078\n",
      "   ‚úÖ Wonyoung: similarity=0.6865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 586/909 [00:17<00:09, 35.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7158\n",
      "   ‚úÖ Gaeul: similarity=0.6836\n",
      "   ‚úÖ Wonyoung: similarity=0.6506\n",
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7039\n",
      "   ‚úÖ Gaeul: similarity=0.6849\n",
      "   ‚úÖ Wonyoung: similarity=0.6063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 596/909 [00:17<00:08, 35.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7149\n",
      "   ‚úÖ Gaeul: similarity=0.6874\n",
      "   ‚úÖ Wonyoung: similarity=0.6847\n",
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7275\n",
      "   ‚úÖ Gaeul: similarity=0.6914\n",
      "   ‚úÖ Wonyoung: similarity=0.6474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 606/909 [00:17<00:08, 34.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 3 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7330\n",
      "   ‚úÖ Gaeul: similarity=0.6721\n",
      "   ‚úÖ Wonyoung: similarity=0.6617\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7134\n",
      "   ‚úÖ Gaeul: similarity=0.6649\n",
      "   ‚úÖ Liz: similarity=0.6709\n",
      "   ‚úÖ Rei: similarity=0.5745\n",
      "   ‚úÖ Yujin: similarity=0.5820\n",
      "   ‚úÖ Wonyoung: similarity=0.6289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 616/909 [00:18<00:12, 24.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7091\n",
      "   ‚úÖ Liz: similarity=0.6622\n",
      "   ‚úÖ Gaeul: similarity=0.6346\n",
      "   ‚úÖ Rei: similarity=0.5712\n",
      "   ‚úÖ Wonyoung: similarity=0.6582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 621/909 [00:18<00:12, 22.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7396\n",
      "   ‚úÖ Rei: similarity=0.5940\n",
      "   ‚úÖ Liz: similarity=0.6648\n",
      "   ‚úÖ Gaeul: similarity=0.6647\n",
      "   ‚úÖ Yujin: similarity=0.4601\n",
      "   ‚úÖ Wonyoung: similarity=0.6757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 626/909 [00:18<00:13, 21.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Gaeul: similarity=0.5781\n",
      "   ‚úÖ Rei: similarity=0.5961\n",
      "   ‚úÖ Leeseo: similarity=0.7316\n",
      "   ‚úÖ Liz: similarity=0.6508\n",
      "   ‚úÖ Wonyoung: similarity=0.6129\n",
      "   ‚úÖ Yujin: similarity=0.5720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 631/909 [00:19<00:13, 20.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5746\n",
      "   ‚úÖ Gaeul: similarity=0.5457\n",
      "   ‚úÖ Leeseo: similarity=0.7532\n",
      "   ‚úÖ Liz: similarity=0.6826\n",
      "   ‚úÖ Wonyoung: similarity=0.5347\n",
      "   ‚úÖ Yujin: similarity=0.5170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 636/909 [00:19<00:11, 22.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5780\n",
      "   ‚úÖ Gaeul: similarity=0.5781\n",
      "   ‚úÖ Liz: similarity=0.6918\n",
      "   ‚úÖ Leeseo: similarity=0.6717\n",
      "   ‚úÖ Yujin: similarity=0.5750\n",
      "   ‚úÖ Wonyoung: similarity=0.6220\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5872\n",
      "   ‚úÖ Leeseo: similarity=0.6471\n",
      "   ‚úÖ Gaeul: similarity=0.5984\n",
      "   ‚úÖ Liz: similarity=0.6942\n",
      "   ‚úÖ Wonyoung: similarity=0.6230\n",
      "   ‚úÖ Yujin: similarity=0.5527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 646/909 [00:19<00:10, 26.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5864\n",
      "   ‚úÖ Gaeul: similarity=0.6061\n",
      "   ‚úÖ Liz: similarity=0.6964\n",
      "   ‚úÖ Leeseo: similarity=0.6653\n",
      "   ‚úÖ Yujin: similarity=0.5529\n",
      "   ‚úÖ Wonyoung: similarity=0.5164\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5511\n",
      "   ‚úÖ Liz: similarity=0.6691\n",
      "   ‚úÖ Gaeul: similarity=0.5445\n",
      "   ‚úÖ Leeseo: similarity=0.7014\n",
      "   ‚úÖ Wonyoung: similarity=0.6052\n",
      "   ‚úÖ Yujin: similarity=0.5510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 656/909 [00:19<00:09, 27.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5548\n",
      "   ‚úÖ Liz: similarity=0.6836\n",
      "   ‚úÖ Gaeul: similarity=0.6645\n",
      "   ‚úÖ Leeseo: similarity=0.6642\n",
      "   ‚úÖ Wonyoung: similarity=0.6591\n",
      "   ‚úÖ Yujin: similarity=0.5601\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5539\n",
      "   ‚úÖ Liz: similarity=0.6510\n",
      "   ‚úÖ Gaeul: similarity=0.6705\n",
      "   ‚úÖ Leeseo: similarity=0.6713\n",
      "   ‚úÖ Yujin: similarity=0.6103\n",
      "   ‚úÖ Wonyoung: similarity=0.6158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 666/909 [00:20<00:08, 28.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5550\n",
      "   ‚úÖ Liz: similarity=0.6584\n",
      "   ‚úÖ Gaeul: similarity=0.6448\n",
      "   ‚úÖ Leeseo: similarity=0.6667\n",
      "   ‚úÖ Yujin: similarity=0.6377\n",
      "   ‚úÖ Wonyoung: similarity=0.6186\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5943\n",
      "   ‚úÖ Liz: similarity=0.6587\n",
      "   ‚úÖ Gaeul: similarity=0.6570\n",
      "   ‚úÖ Leeseo: similarity=0.6334\n",
      "   ‚úÖ Yujin: similarity=0.6127\n",
      "   ‚úÖ Wonyoung: similarity=0.6781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 676/909 [00:20<00:08, 28.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Liz: similarity=0.6566\n",
      "   ‚úÖ Rei: similarity=0.5931\n",
      "   ‚úÖ Gaeul: similarity=0.6650\n",
      "   ‚úÖ Yujin: similarity=0.6119\n",
      "   ‚úÖ Leeseo: similarity=0.6582\n",
      "   ‚úÖ Wonyoung: similarity=0.6587\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Liz: similarity=0.6560\n",
      "   ‚úÖ Rei: similarity=0.5347\n",
      "   ‚úÖ Gaeul: similarity=0.6577\n",
      "   ‚úÖ Yujin: similarity=0.6433\n",
      "   ‚úÖ Leeseo: similarity=0.6989\n",
      "   ‚úÖ Wonyoung: similarity=0.6664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 686/909 [00:21<00:07, 29.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Liz: similarity=0.6520\n",
      "   ‚úÖ Rei: similarity=0.5112\n",
      "   ‚úÖ Gaeul: similarity=0.6344\n",
      "   ‚úÖ Yujin: similarity=0.6020\n",
      "   ‚úÖ Leeseo: similarity=0.6325\n",
      "   ‚úÖ Wonyoung: similarity=0.6749\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Liz: similarity=0.6377\n",
      "   ‚úÖ Gaeul: similarity=0.6279\n",
      "   ‚úÖ Yujin: similarity=0.6118\n",
      "   ‚úÖ Rei: similarity=0.5247\n",
      "   ‚úÖ Leeseo: similarity=0.6037\n",
      "   ‚úÖ Wonyoung: similarity=0.6336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 696/909 [00:21<00:07, 29.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Liz: similarity=0.6401\n",
      "   ‚úÖ Leeseo: similarity=0.6773\n",
      "   ‚úÖ Rei: similarity=0.5246\n",
      "   ‚úÖ Gaeul: similarity=0.6184\n",
      "   ‚úÖ Yujin: similarity=0.6084\n",
      "   ‚úÖ Wonyoung: similarity=0.5973\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Liz: similarity=0.6323\n",
      "   ‚úÖ Leeseo: similarity=0.6708\n",
      "   ‚úÖ Gaeul: similarity=0.6389\n",
      "   ‚úÖ Rei: similarity=0.5622\n",
      "   ‚úÖ Yujin: similarity=0.6038\n",
      "   ‚úÖ Wonyoung: similarity=0.5250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 706/909 [00:21<00:06, 29.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5309\n",
      "   ‚úÖ Liz: similarity=0.6170\n",
      "   ‚úÖ Gaeul: similarity=0.6318\n",
      "   ‚úÖ Leeseo: similarity=0.6722\n",
      "   ‚úÖ Yujin: similarity=0.5829\n",
      "   ‚úÖ Wonyoung: similarity=0.5076\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5436\n",
      "   ‚úÖ Liz: similarity=0.6427\n",
      "   ‚úÖ Gaeul: similarity=0.6042\n",
      "   ‚úÖ Leeseo: similarity=0.6800\n",
      "   ‚úÖ Yujin: similarity=0.6002\n",
      "   ‚úÖ Wonyoung: similarity=0.4838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 716/909 [00:22<00:06, 29.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5289\n",
      "   ‚úÖ Liz: similarity=0.6466\n",
      "   ‚úÖ Gaeul: similarity=0.5679\n",
      "   ‚úÖ Leeseo: similarity=0.6827\n",
      "   ‚úÖ Yujin: similarity=0.5798\n",
      "   ‚úÖ Wonyoung: similarity=0.5187\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Gaeul: similarity=0.6163\n",
      "   ‚úÖ Liz: similarity=0.6103\n",
      "   ‚úÖ Rei: similarity=0.4819\n",
      "   ‚úÖ Leeseo: similarity=0.7228\n",
      "   ‚úÖ Yujin: similarity=0.5880\n",
      "   ‚úÖ Wonyoung: similarity=0.5406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 726/909 [00:22<00:06, 29.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Gaeul: similarity=0.6279\n",
      "   ‚úÖ Liz: similarity=0.6508\n",
      "   ‚úÖ Rei: similarity=0.4949\n",
      "   ‚úÖ Leeseo: similarity=0.7670\n",
      "   ‚úÖ Yujin: similarity=0.6099\n",
      "   ‚úÖ Wonyoung: similarity=0.4715\n",
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 741/909 [00:22<00:04, 39.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 751/909 [00:22<00:03, 43.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 801/909 [00:23<00:00, 139.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Gaeul: similarity=0.6050\n",
      "   ‚úÖ Leeseo: similarity=0.7649\n",
      "   ‚úÖ Liz: similarity=0.6876\n",
      "   ‚úÖ Rei: similarity=0.6261\n",
      "   ‚úÖ Yujin: similarity=0.6129\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Gaeul: similarity=0.6177\n",
      "   ‚úÖ Liz: similarity=0.6721\n",
      "   ‚úÖ Rei: similarity=0.6364\n",
      "   ‚úÖ Leeseo: similarity=0.7563\n",
      "   ‚úÖ Yujin: similarity=0.5904\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Liz: similarity=0.6707\n",
      "   ‚úÖ Gaeul: similarity=0.6315\n",
      "   ‚úÖ Leeseo: similarity=0.7448\n",
      "   ‚úÖ Rei: similarity=0.5458\n",
      "   ‚úÖ Wonyoung: similarity=0.5552\n",
      "   ‚úÖ Yujin: similarity=0.5972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 816/909 [00:23<00:01, 80.73it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Gaeul: similarity=0.6033\n",
      "   ‚úÖ Rei: similarity=0.5592\n",
      "   ‚úÖ Liz: similarity=0.6678\n",
      "   ‚úÖ Leeseo: similarity=0.7116\n",
      "   ‚úÖ Yujin: similarity=0.5146\n",
      "   ‚úÖ Wonyoung: similarity=0.5517\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Gaeul: similarity=0.6266\n",
      "   ‚úÖ Rei: similarity=0.6241\n",
      "   ‚úÖ Liz: similarity=0.6808\n",
      "   ‚úÖ Leeseo: similarity=0.7083\n",
      "   ‚úÖ Yujin: similarity=0.4652\n",
      "   ‚úÖ Wonyoung: similarity=0.5581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 828/909 [00:23<00:01, 61.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Gaeul: similarity=0.6051\n",
      "   ‚úÖ Liz: similarity=0.6854\n",
      "   ‚úÖ Leeseo: similarity=0.6681\n",
      "   ‚úÖ Rei: similarity=0.6043\n",
      "   ‚úÖ Yujin: similarity=0.5391\n",
      "   ‚úÖ Wonyoung: similarity=0.5996\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Gaeul: similarity=0.6808\n",
      "   ‚úÖ Rei: similarity=0.5409\n",
      "   ‚úÖ Liz: similarity=0.6812\n",
      "   ‚úÖ Leeseo: similarity=0.7214\n",
      "   ‚úÖ Wonyoung: similarity=0.6200\n",
      "   ‚úÖ Yujin: similarity=0.5858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 838/909 [00:24<00:01, 49.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5605\n",
      "   ‚úÖ Liz: similarity=0.6679\n",
      "   ‚úÖ Gaeul: similarity=0.5890\n",
      "   ‚úÖ Wonyoung: similarity=0.6506\n",
      "   ‚úÖ Yujin: similarity=0.5823\n",
      "   ‚úÖ Leeseo: similarity=0.5609\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7022\n",
      "   ‚úÖ Liz: similarity=0.6326\n",
      "   ‚úÖ Rei: similarity=0.4892\n",
      "   ‚úÖ Gaeul: similarity=0.5880\n",
      "   ‚úÖ Wonyoung: similarity=0.6498\n",
      "   ‚úÖ Yujin: similarity=0.5347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 852/909 [00:24<00:01, 39.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.6969\n",
      "   ‚úÖ Yujin: similarity=0.5902\n",
      "   ‚úÖ Rei: similarity=0.5823\n",
      "   ‚úÖ Liz: similarity=0.7055\n",
      "   ‚úÖ Gaeul: similarity=0.6161\n",
      "   ‚úÖ Wonyoung: similarity=0.6583\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.6849\n",
      "   ‚úÖ Rei: similarity=0.5101\n",
      "   ‚úÖ Yujin: similarity=0.5959\n",
      "   ‚úÖ Liz: similarity=0.6991\n",
      "   ‚úÖ Gaeul: similarity=0.6443\n",
      "   ‚úÖ Wonyoung: similarity=0.6614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 863/909 [00:24<00:01, 36.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.6702\n",
      "   ‚úÖ Gaeul: similarity=0.6038\n",
      "   ‚úÖ Rei: similarity=0.5107\n",
      "   ‚úÖ Yujin: similarity=0.5949\n",
      "   ‚úÖ Liz: similarity=0.6862\n",
      "   ‚úÖ Wonyoung: similarity=0.6546\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5195\n",
      "   ‚úÖ Leeseo: similarity=0.6391\n",
      "   ‚úÖ Gaeul: similarity=0.5933\n",
      "   ‚úÖ Liz: similarity=0.6559\n",
      "   ‚úÖ Yujin: similarity=0.6371\n",
      "   ‚úÖ Wonyoung: similarity=0.6549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 872/909 [00:25<00:01, 32.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Rei: similarity=0.5171\n",
      "   ‚úÖ Leeseo: similarity=0.6586\n",
      "   ‚úÖ Gaeul: similarity=0.6222\n",
      "   ‚úÖ Liz: similarity=0.6444\n",
      "   ‚úÖ Yujin: similarity=0.6422\n",
      "   ‚úÖ Wonyoung: similarity=0.6491\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.6931\n",
      "   ‚úÖ Gaeul: similarity=0.6214\n",
      "   ‚úÖ Rei: similarity=0.5203\n",
      "   ‚úÖ Liz: similarity=0.6723\n",
      "   ‚úÖ Yujin: similarity=0.6179\n",
      "   ‚úÖ Wonyoung: similarity=0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 881/909 [00:25<00:00, 29.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7120\n",
      "   ‚úÖ Rei: similarity=0.5401\n",
      "   ‚úÖ Gaeul: similarity=0.6369\n",
      "   ‚úÖ Liz: similarity=0.6621\n",
      "   ‚úÖ Yujin: similarity=0.5466\n",
      "   ‚úÖ Wonyoung: similarity=0.6244\n",
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7155\n",
      "   ‚úÖ Gaeul: similarity=0.6481\n",
      "   ‚úÖ Rei: similarity=0.5564\n",
      "   ‚úÖ Liz: similarity=0.6375\n",
      "   ‚úÖ Yujin: similarity=0.5886\n",
      "   ‚úÖ Wonyoung: similarity=0.6401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 891/909 [00:25<00:00, 29.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7399\n",
      "   ‚úÖ Gaeul: similarity=0.5889\n",
      "   ‚úÖ Rei: similarity=0.5928\n",
      "   ‚úÖ Liz: similarity=0.6608\n",
      "   ‚úÖ Wonyoung: similarity=0.6402\n",
      "   ‚úÖ Yujin: similarity=0.5493\n",
      "üîç ‡∏û‡∏ö 5 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7441\n",
      "   ‚úÖ Gaeul: similarity=0.5420\n",
      "   ‚úÖ Rei: similarity=0.5623\n",
      "   ‚úÖ Liz: similarity=0.6711\n",
      "   ‚úÖ Wonyoung: similarity=0.6644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 901/909 [00:26<00:00, 29.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ‡∏û‡∏ö 6 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7155\n",
      "   ‚úÖ Liz: similarity=0.6848\n",
      "   ‚úÖ Wonyoung: similarity=0.5899\n",
      "üîç ‡∏û‡∏ö 5 ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û\n",
      "   ‚úÖ Leeseo: similarity=0.7344\n",
      "   ‚úÖ Liz: similarity=0.6979\n",
      "   ‚úÖ Wonyoung: similarity=0.6262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 909/909 [00:26<00:00, 34.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• 182 frames\n",
      "   ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏µ‡πà: outputs/segmented_wonyoung.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'outputs/segmented_wonyoung.mp4'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠)\n",
    "input_video = \"Input/IVE-30s.mp4\"\n",
    "output_video = \"outputs/segmented_wonyoung.mp4\"\n",
    "process_video(input_video, output_video, \"Wonyoung\", frame_sampling=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéâ ‡∏™‡∏£‡∏∏‡∏õ\n",
    "\n",
    "‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏ô‡∏µ‡πâ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢:\n",
    "1. ‚úÖ Environment Setup - ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á dependencies\n",
    "2. ‚úÖ Face Embedding Database - ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö IVE\n",
    "3. ‚úÖ Identity Matching - ‡∏£‡∏∞‡∏ö‡∏∏‡∏ï‡∏±‡∏ß‡∏ï‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Hungarian Algorithm\n",
    "4. ‚úÖ SAM 3 Engine - Segmentation ‡∏î‡πâ‡∏ß‡∏¢ box prompt\n",
    "5. ‚úÖ Integration Pipeline - ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô\n",
    "6. ‚úÖ Gradio UI - Web interface ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\n",
    "7. ‚úÖ Video Inference - ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏û‡∏£‡πâ‡∏≠‡∏° tracking\n",
    "\n",
    "**‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ö‡∏ô RTX 6000 (48GB VRAM)!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
